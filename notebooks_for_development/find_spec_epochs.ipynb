{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This plots the epochs at which RR Lyrae spectra were taken\n",
    "\n",
    "# created 2017 Dec 19 by E.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import astropy\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "from astropy import time, coordinates as coord, units as u\n",
    "from astropy.time import Time\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stem = '/home/../../media/unasemaje/Seagate Expansion Drive/rrlyrae_data_reduction/unnorm_fits_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "arr_files = os.listdir(stem) # list files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in each FITS file in the directory and obtain epoch from header\n",
    "\n",
    "fileList_2012 = []\n",
    "dateList_2012 = []\n",
    "fileList_2013 = []\n",
    "dateList_2013 = []\n",
    "for f in range(0,len(arr_files)): # loop over filenames\n",
    "    \n",
    "    # retrieve header\n",
    "    image, header = fits.getdata(stem+arr_files[f],\n",
    "                                     0,\n",
    "                                     header=True)\n",
    "    \n",
    "    # observation epoch\n",
    "    epoch = header['DATE-OBS']+' '+header['UT']\n",
    "    \n",
    "    # parse\n",
    "    epoch_dateTime = datetime.strptime(epoch, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    if (epoch_dateTime.year == 2012):\n",
    "        fileList_2012.append(arr_files[f])\n",
    "        dateList_2012.append(epoch_dateTime)\n",
    "    else:\n",
    "        fileList_2013.append(arr_files[f])\n",
    "        dateList_2013.append(epoch_dateTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## MAKE PLOTS\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fcn for generating a plot to visualize epochs\n",
    "\n",
    "def spec_epoch_plot(fileArray,epochArray,plotName):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(200, 10)\n",
    "    ax.scatter(epochArray, np.ones(len(epochArray)))\n",
    "    \n",
    "    #textPos = np.max(spectData.flux)+0.01\n",
    "    [ax.text(epochArray[i], 2.5, fileArray[i], rotation='vertical') for i in range(len(epochArray))]\n",
    "    \n",
    "    ax.set_ylim([0,3.6])\n",
    "    ax.set_xlim([np.min(epochArray),np.max(epochArray)])\n",
    "    plt.savefig(plotName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write out plots of when spectra were observed\n",
    "\n",
    "spec_epoch_plot(fileList_2012,dateList_2012,'test_2012.pdf')\n",
    "spec_epoch_plot(fileList_2013,dateList_2013,'test_2013.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## FIND ELAPSED BJDS\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set observatory coordinates \n",
    "\n",
    "loc_mcdonald = coord.EarthLocation.from_geodetic(lon=-104.0215753,lat=30.6715396,height=2076,ellipsoid='WGS84')\n",
    "loc_macadam = coord.EarthLocation.from_geodetic(lon=-84.503712,lat=38.033891,height=298,ellipsoid='WGS84')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert UTC times to isot format, then compile into list of astropy Time object\n",
    "\n",
    "t_spectra_2012_iso = [Time(dateList_2012[i].isoformat(), format='isot', scale='utc') for i in range(len(dateList_2012))]\n",
    "t_spectra_2013_iso = [Time(dateList_2013[i].isoformat(), format='isot', scale='utc') for i in range(len(dateList_2013))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert isot-format times to MJD or JD (Astropy seems to make more accurate conversion from MJD->BJD) \n",
    "\n",
    "t_spectra_2012_mjd = [t_spectra_2012_iso[i].mjd for i in range(len(t_spectra_2012_iso))]\n",
    "t_spectra_2013_mjd = [t_spectra_2013_iso[i].mjd for i in range(len(t_spectra_2013_iso))]\n",
    "\n",
    "t_spectra_2012_jd = [t_spectra_2012_iso[i].jd for i in range(len(t_spectra_2012_iso))]\n",
    "t_spectra_2013_jd = [t_spectra_2013_iso[i].jd for i in range(len(t_spectra_2013_iso))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fcn to convert MJD to BJD times\n",
    "\n",
    "def convert_mjd_to_bjd(mjdTimes,observatoryLoc,skyCoordObj):\n",
    "\n",
    "    timesObj = time.Time(mjdTimes, format='mjd', scale='utc', location=observatoryLoc)\n",
    "    ltt_bary = timesObj.light_travel_time(skyCoordObj)\n",
    "    \n",
    "    time_barycentre = timesObj.tdb + ltt_bary \n",
    "        \n",
    "    # note the returned type is still mendaciously called 'mjd' \n",
    "    return np.add(time_barycentre.mjd,0.5) # I think 0.5 day is missing from the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fcn to convert MJD to HJD times\n",
    "\n",
    "def convert_mjd_to_hjd(mjdTimes,observatoryLoc,skyCoordObj):\n",
    "\n",
    "    timesObj = time.Time(mjdTimes, format='mjd', scale='utc', location=observatoryLoc)\n",
    "    ltt_helio = timesObj.light_travel_time(skyCoordObj, 'heliocentric')\n",
    "    \n",
    "    times_heliocentre = timesObj.utc + ltt_helio \n",
    "        \n",
    "    # note the returned type is still mendaciously called 'mjd' \n",
    "    return np.add(times_heliocentre.mjd,0.5) # I think 0.5 day is missing from the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine all data for across-the-board comparison\n",
    "\n",
    "allFileList = np.hstack((fileList_2012,fileList_2013))\n",
    "allSpecEpochList_utc = np.hstack((dateList_2012,dateList_2013))\n",
    "allSpecEpochList_mjd = np.hstack((t_spectra_2012_mjd,t_spectra_2013_mjd))\n",
    "allSpecEpochList_jd = np.hstack((t_spectra_2012_jd,t_spectra_2013_jd))\n",
    "#allSpecEpochList_bjd = np.hstack((t_spectra_2012_bjd,t_spectra_2013_bjd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in star name, return file names and BJDs of spectra observations\n",
    "\n",
    "def return_star_bjds(fileNames,mjdTimes,starNameFile,starNameGeneric,observatoryLoc):\n",
    "    \n",
    "    if len(fileNames) != len(mjdTimes): # something must be wrong!\n",
    "        return\n",
    "    \n",
    "    # initialize a pandas dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # make a star coordinate object\n",
    "    coord_star = coord.SkyCoord.from_name(starNameGeneric)\n",
    "    \n",
    "    fileNamesThisStar = []\n",
    "    mjdsThisStar = []\n",
    "    hjdsThisStar = []\n",
    "    bjdsThisStar = []\n",
    "    for t in range(0,len(fileNames)):            \n",
    "        if starNameFile in fileNames[t]:\n",
    "            fileNamesThisStar.append(fileNames[t])\n",
    "            mjdsThisStar.append(mjdTimes[t])\n",
    "            hjdsThisStar.append(convert_mjd_to_hjd(mjdTimes[t],observatoryLoc,coord_star))\n",
    "            bjdsThisStar.append(convert_mjd_to_bjd(mjdTimes[t],observatoryLoc,coord_star)) \n",
    "    \n",
    "    #bjdsThisStar = np.add(bjdsThisStar,0.5)  # I think 0.5 day is missing from the code\n",
    "    elapsed_bjd = np.subtract(bjdsThisStar,np.min(bjdsThisStar))\n",
    "    \n",
    "    df['filenames'] = fileNamesThisStar\n",
    "    df['mjd'] = mjdsThisStar\n",
    "    df['hjd'] = hjdsThisStar\n",
    "    df['bjd'] = bjdsThisStar\n",
    "    df['elapsed_bjd_since_spec_01'] = elapsed_bjd\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# star names as they appear in the filenames\n",
    "star_names_files = ['RW_Ari','X_Ari','UY_Cam','RR_Cet','SV_Eri',\n",
    "              'VX_Her','RR_Leo','TT_Lyn','TV_Lyn','TW_Lyn',\n",
    "              'RR_Lyr','V_535','V445','AV_Peg','BH_Peg',\n",
    "              'AR_Per','RU_Psc','T_Sex','TU_UMa']\n",
    "\n",
    "# star names for SIMBAD lookup\n",
    "star_names_simbad = ['RW Ari','X Ari','UY Cam','RR Cet','SV Eri',\n",
    "              'VX Her','RR Leo','TT Lyn','TV Lyn','TW Lyn',\n",
    "              'RR Lyr','V535 Mon','V445 Oph','AV Peg','BH Peg',\n",
    "              'AR Per','RU Psc','T Sex','TU UMa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find BJDs and concatenate everything into one dataframe\n",
    "\n",
    "dfAll = pd.DataFrame()\n",
    "for star in range(0,len(star_names_files)):\n",
    "    df_thisStar = return_star_bjds(allFileList,allSpecEpochList_mjd,star_names_files[star],star_names_simbad[star],loc_mcdonald)\n",
    "    dfAll = pd.concat([dfAll,df_thisStar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write out csv\n",
    "\n",
    "dfAll.to_csv('junk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>mjd</th>\n",
       "      <th>hjd</th>\n",
       "      <th>bjd</th>\n",
       "      <th>elapsed_bjd_since_spec_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RW_Ari_02.fits</td>\n",
       "      <td>56288.129929</td>\n",
       "      <td>56288.632936</td>\n",
       "      <td>56288.633699</td>\n",
       "      <td>0.039824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RW_Ari_01.fits</td>\n",
       "      <td>56288.090101</td>\n",
       "      <td>56288.593111</td>\n",
       "      <td>56288.593874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RW_Ari_03.fits</td>\n",
       "      <td>56288.169575</td>\n",
       "      <td>56288.672579</td>\n",
       "      <td>56288.673341</td>\n",
       "      <td>0.079467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RW_Ari_04.fits</td>\n",
       "      <td>56289.084369</td>\n",
       "      <td>56289.587294</td>\n",
       "      <td>56289.588057</td>\n",
       "      <td>0.994182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RW_Ari_05.fits</td>\n",
       "      <td>56289.135552</td>\n",
       "      <td>56289.638472</td>\n",
       "      <td>56289.639235</td>\n",
       "      <td>1.045361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filenames           mjd           hjd           bjd  \\\n",
       "0  RW_Ari_02.fits  56288.129929  56288.632936  56288.633699   \n",
       "1  RW_Ari_01.fits  56288.090101  56288.593111  56288.593874   \n",
       "2  RW_Ari_03.fits  56288.169575  56288.672579  56288.673341   \n",
       "3  RW_Ari_04.fits  56289.084369  56289.587294  56289.588057   \n",
       "4  RW_Ari_05.fits  56289.135552  56289.638472  56289.639235   \n",
       "\n",
       "   elapsed_bjd_since_spec_01  \n",
       "0                   0.039824  \n",
       "1                   0.000000  \n",
       "2                   0.079467  \n",
       "3                   0.994182  \n",
       "4                   1.045361  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show\n",
    "\n",
    "dfAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
