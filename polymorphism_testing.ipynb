{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some functions that will be used in the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_highres_w_basis(self):\n",
    "    '''\n",
    "    Find what stars overlap with basis data set, and return star name, data set names, FeH values, residuals\n",
    "\n",
    "    The functionality of LitMetallicities is inherited\n",
    "    N.b. There are no offsets applied yet (as are applied in Chadid+ 2017 plots)\n",
    "\n",
    "    INPUTS:\n",
    "    input_table: table of high-res-derived Fe/H values, which I want to cross-ref with a basis (like Layden 94 or Kemper 82)\n",
    "    basis_table: the table which serves as the basis set\n",
    "    plot_name: file name for saving a plot of the results\n",
    "\n",
    "    OUTPUTS:\n",
    "    df: concatenated frames containing \n",
    "    ['name_star']: star_name_array\n",
    "    ['FeH_highres']: Fe/H from high-res study\n",
    "    ['FeH_basis']: Fe/H from basis set\n",
    "    ['name_highres_dataset']: string indicating the high-res dataset\n",
    "    ['name_basis_dataset']: string indicating the basis set\n",
    "    '''\n",
    "\n",
    "    # define the basis data set (like Layden 1994 for RRabs, or Kemper+ 1982 for RRcs)\n",
    "    if self.__star_type == \"RRab\":\n",
    "        type_string = \"ab\"\n",
    "        basis_set = self.layden_feh\n",
    "        basis_string = \"Layden RRab basis set\" # string for plots\n",
    "    elif self.__star_type == \"RRc\":\n",
    "        type_string = \"c\"\n",
    "        basis_set = self.kemper_feh\n",
    "        basis_string = \"Kemper RRc basis set\"\n",
    "    else:\n",
    "        sys.exit(\"Error! No RR Lyrae subtype chosen.\")\n",
    "\n",
    "\n",
    "    ## match ALL available high-res studies with the basis set\n",
    "\n",
    "    pd_Lambert_1996 = self.matchmaker(self.lambert_logeps, \n",
    "                                      basis_set, \n",
    "                                      highres_dataset_name=\"lambert_1996\") # Lambert+ 1996 (logeps has already been converted to Fe/H)\n",
    "    pd_Nemec_2013 = self.matchmaker(self.nemec_feh, \n",
    "                                    basis_set,\n",
    "                                    highres_dataset_name=\"nemec_2013\") # Nemec+ 2013\n",
    "    pd_Chadid_2017 = self.matchmaker(self.chadid_feh, \n",
    "                                     basis_set,\n",
    "                                     highres_dataset_name=\"chadid_2017\") # Chadid+ 2017\n",
    "    pd_Fernley_1997 = self.matchmaker(self.fernley97_feh, \n",
    "                                      basis_set,\n",
    "                                      highres_dataset_name=\"fernley_1997\") # Fernley+ 1997\n",
    "    pd_Solano_1997 = self.matchmaker(self.solano_feh, \n",
    "                                     basis_set,\n",
    "                                     highres_dataset_name=\"solano_1997\") # Solano+ 1997\n",
    "    pd_Wallerstein_2010 = self.matchmaker(self.wallerstein_feh, \n",
    "                                          basis_set,\n",
    "                                          highres_dataset_name=\"wallerstein_2010\") # Wallerstein 2010\n",
    "\n",
    "    # for Liu+ 2013, we need to group multiple Fe/H values by star name\n",
    "    # (the grouping is done here rather than further up because a bug causes the grouped column to disappear)\n",
    "    self.liu_feh_grouped = self.liu_feh.groupby(self.liu_feh['name'], axis=0, as_index=False).mean()\n",
    "    pd_Liu_2013 = self.matchmaker(self.liu_feh_grouped, \n",
    "                                  basis_set,\n",
    "                                  highres_dataset_name=\"liu_2013\") # Liu+ 2013\n",
    "\n",
    "    # for Govea+ 2014, we need to group multiple Fe/H_I and Fe/H_II values by star name\n",
    "    # (the grouping is done here rather than further upstream because otherwise a bug causes \n",
    "    # the grouped column to disappear)\n",
    "    self.govea_feh_grouped = self.govea_feh.groupby(self.govea_feh['name'], axis=0, as_index=False).mean()\n",
    "    # now, average the Fe/H_I and Fe/H_II values to get single Fe/H values\n",
    "    self.govea_feh_grouped['feh'] = self.govea_feh_grouped[['feIh','feIIh']].mean(axis=1)\n",
    "    pd_Govea_2014 = self.matchmaker(self.govea_feh_grouped, \n",
    "                                    basis_set,\n",
    "                                    highres_dataset_name=\"govea_2014\") # Govea+ 2014\n",
    "\n",
    "    # merge dataframes\n",
    "    pd_collected = [pd_Lambert_1996, pd_Nemec_2013, pd_Liu_2013, pd_Chadid_2017,\n",
    "                    pd_Fernley_1997, pd_Solano_1997, pd_Wallerstein_2010, pd_Govea_2014]\n",
    "    df = pd.concat(pd_collected).reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_offsets(data_postmatch, chadid_offset=True):\n",
    "    '''\n",
    "    Fit linear regression to input high-res Fe/H and the basis set,\n",
    "    and find offset for each dataset to match some constant\n",
    "    \n",
    "    INPUTS:\n",
    "    data_postmatch: output from match_w_highres_basis(), containing\n",
    "        Fe/H data from high-res studies and basis set\n",
    "        \n",
    "    OUTPUTS:\n",
    "    df: dataframe containing\n",
    "    ['name_highres_dataset']: name indicating high-res study\n",
    "    ['offset_highres_dataset_residuals']: offset for the entire high-res \n",
    "        dataset, which needs to be applied to the vector (FeH_highres-FeH_basis)\n",
    "    '''\n",
    "    \n",
    "    # initialize dataframe\n",
    "    col_names =  [\"name_highres\", \"offset_highres_residuals\"]\n",
    "    df_offsets  = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    # loop over each high-res dataset\n",
    "    highres_names = data_postmatch[\"name_highres_dataset\"].unique() # names of high-res datasets\n",
    "    for dataset_num in range(0,len(highres_names)):\n",
    "        \n",
    "        this_dataset_name = highres_names[dataset_num] # name of this dataset\n",
    "        this_dataset = data_postmatch[data_postmatch[\"name_highres_dataset\"].str.match(this_dataset_name)]\n",
    "    \n",
    "    \n",
    "        # find linear regression of residuals\n",
    "        coeff = np.polyfit(this_dataset[\"FeH_basis\"],\n",
    "                           np.subtract(this_dataset[\"FeH_highres\"],\n",
    "                                       this_dataset[\"FeH_basis\"]),1)\n",
    "        limits = [-3.0,0.5] # Fe/H limits to display\n",
    "        line = np.multiply(coeff[0],limits)+coeff[1] # points to plot linear regression\n",
    "\n",
    "        # find offset between residuals and Chadid+ 2017 at Fe/H=-1.25 (see their Fig. 6)\n",
    "        if chadid_offset: \n",
    "            chadid_y_125 = -0.10583621694962 # from Chadid line at Fe/H=-1.25\n",
    "            FeH_resid_to_peg = chadid_y_125 # peg the FeH residuals to this y- point\n",
    "            FeH_basis_loc = -1.25 # corresponding x- value (Fe/H in the basis dataset)\n",
    "        else: \n",
    "            FeH_resid_to_peg = 0. # peg the data at this y- point\n",
    "            FeH_basis_loc = 0. # location in the basis dataset \n",
    "            print(\"Offset corresponds to (0,0)!\")\n",
    "\n",
    "        # y-value of the unshifted linear regression line at Fe/H=-1.25\n",
    "        this_y_125 = np.multiply(coeff[0],FeH_basis_loc)+coeff[1] \n",
    "\n",
    "        # offset to shift the linear regression line of the residuals to FeH_resid_to_peg\n",
    "        net_offset = chadid_y_125 - this_y_125\n",
    "\n",
    "        # line_offset = np.add(line,net_offset)\n",
    "\n",
    "        print('-----------------')\n",
    "        print('Calculating offsets for dataset '+this_dataset_name)\n",
    "        print('Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:')\n",
    "        print(net_offset)\n",
    "        print('Number of overlapping stars:')\n",
    "        print(len(residuals))\n",
    "\n",
    "        # append name of dataset and its offset to array\n",
    "        dict_this = {\"name_highres\":this_dataset_name,\n",
    "                     \"offset_highres_residuals\":net_offset}\n",
    "        df_offsets = df_offsets.append(pd.DataFrame(dict_this))\n",
    " \n",
    "    return df_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_basis_via_offsets(df_to_offset,df_offsets):\n",
    "    '''\n",
    "    Apply offsets (which may be from RRabs, RRcs, combo, etc.) to data to make a basis\n",
    "\n",
    "    INPUTS:\n",
    "    df_to_offset: dataframe containing Fe/H values which we want to find residuals for, offset, and map\n",
    "        ['name_star']: star name\n",
    "        ['FeH_highres']: Fe/H from high-res study\n",
    "        ['FeH_basis']: Fe/H from basis set\n",
    "        ['name_highres_dataset']: string indicating the high-res dataset\n",
    "        ['name_basis_dataset']: string indicating the basis set\n",
    "          \n",
    "    df_offsets: dataframe containing the offset values and high-res dataset names\n",
    "        ['name_highres_dataset']: name indicating high-res study\n",
    "        ['offset_highres_dataset_residuals']: offset value to add to Fe/H values\n",
    "    '''\n",
    "\n",
    "    dict_merged_this_basis = {} # initialize dictionaries\n",
    "    dict_not_merged_this_basis = {}\n",
    "    highres_names = df_to_offset[\"name_highres_dataset\"].unique() # names of high-res datasets (which will also be the keys to dict_merged_this_basis)\n",
    "    \n",
    "    # for each high-res dataset name, apply the offsets to Fe/H residuals\n",
    "    for (this_dataset_name in highres_names):    \n",
    "        \n",
    "        this_dataset = df_to_offset[df_to_offset[\"name_highres_dataset\"].str.match(this_dataset_name)]\n",
    "\n",
    "        this_dataset[\"residuals_no_shift\"] = np.subtract(this_dataset[\"FeH_highres\"],this_dataset[\"FeH_basis\"])\n",
    "        this_dataset[\"residuals_shifted\"] = np.add(this_dataset[\"residuals\"],this_dataset[\"offset_highres_residuals\"])\n",
    "\n",
    "        # add dataframe to dictionary; \n",
    "        # each key corresponds to a high-res dataset, and each value is a dataframe (this is good for plotting)\n",
    "        dict_not_merged_this_basis[this_dataset_name] = this_dataset\n",
    "     \n",
    "    # merge [\"residuals_shifted\"] and [\"FeH_highres\"] across all \n",
    "    # dataframes in the dictionary (this is good for finding net Fe/H mapping)\n",
    "    pd_merged = pd.concat(dict_not_merged_this_basis.values(), ignore_index=True)\n",
    "    \n",
    "    # find best-fit line to Fe/H plot of high_res vs. basis \n",
    "    # (note that user may have used a flag to make Fe/H values be offset)\n",
    "    limits = [-3.0,0.5] # Fe/H limits to display\n",
    "    \n",
    "    m_merged_highres, b_merged_highres = np.polyfit(pd_merged[\"FeH_basis\"], pd_merged[\"FeH_highres\"], 1)\n",
    "    line_highres = np.multiply(m_merged_highres,limits)+b_merged_highres # make best-fit line for high-res Fe/H\n",
    "    \n",
    "    m_merged_shifted_resid, b_merged_shifted_resid = np.polyfit(pd_merged[\"FeH_basis\"], pd_merged[\"residuals_shifted\"], 1)\n",
    "    line_shifted_resid = np.multiply(m_merged_shifted_resid,limits)+b_merged_shifted_resid # make best-fit line for residuals\n",
    "\n",
    "    # save a plot (high_res vs. basis on top; residuals vs. basis on bottom)\n",
    "    '''\n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10,10), sharex=True)\n",
    "    axs[0].plot([limits[0],limits[1]],[limits[0],limits[1]], linestyle='--') # make 1-to-1 line\n",
    "    axs[0].plot([limits[0],limits[1]],np.add(np.multiply(m_merged_highres,[limits[0],limits[1]]),b_merged_highres), linestyle='--') # best-fit line\n",
    "    axs[0].scatter(basis_data_merged, highres_data_merged) # input vs. basis\n",
    "    axs[0].set_xlim(limits[0], limits[1])\n",
    "    axs[0].set_ylabel(\"Fe/H, high-res\")\n",
    "    axs[0].set_title(\"m = \"+str(m_merged_highres)+\", b = \"+str(b_merged_highres)+\"; (blue line: 1-to-1; orange line: best fit)\")\n",
    "    axs[1].axhline(y=0, linestyle='--') # dashed line at y=0\n",
    "    axs[1].scatter(basis_data_merged, residuals_data_merged) # input vs. basis\n",
    "    axs[1].set_xlabel(\"Fe/H, \"+basis_string)\n",
    "    axs[1].set_ylabel('Fe/H Residuals: high-res minus basis set')\n",
    "    axs[1].set_title(\"m = \"+str(m_merged_resid)+\", b = \"+str(b_merged_resid)+\"; (blue line: zero)\")\n",
    "    fig.suptitle(\"Finding remapping relation between\\nhigh-res studies and basis dataset\\n(\"+type_string+\" subtype)\")\n",
    "    #fig.tight_layout()\n",
    "    plt.savefig(\"remapping_\"+self.__plot_name, overwrite=True)\n",
    "    plt.clf()\n",
    "    d['coeff_merged_highres'] = [m_merged_highres, b_merged_highres] # best-fit line coeffs for high-res vs. basis \n",
    "    d['coeff_merged_resid'] = [m_merged_resid, b_merged_resid] # best-fit line coeffs for (residuals: high-res minus basis) vs. basis \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LitMetallicities():\n",
    "    '''\n",
    "    Class to \n",
    "    1.   read in Fe/H values from the literature \n",
    "    2.   initialize data set cross-referencing functionality\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        stem = \"./rrlyrae_metallicity/src/high_res_feh/\"\n",
    "\n",
    "        # stand-in that consists of our program star names\n",
    "        self.our_program_stars = pd.read_csv(stem + \"our_program_stars_names_only.csv\")\n",
    "        \n",
    "        # Fe/H from Layden+ 1994; this may serve as the common basis for RRabs\n",
    "        self.layden_feh = pd.read_csv(stem + \"layden_1994_abundances.dat\")\n",
    "        # RES: \"rather low\"\n",
    "        \n",
    "        # Fe/H Clementini+ 1995\n",
    "        self.clementini_feh = pd.read_csv(stem + \"clementini_1995_abundances.dat\")\n",
    "\n",
    "        # Fe/H Fernley+ 1996\n",
    "        self.fernley_feh = pd.read_csv(stem + \"fernley_1996_abundances.dat\")\n",
    "        # RES: 60,000, FeI & FeII, 5900-8100 A\n",
    "        \n",
    "        # log(eps) from Lambert+ 1996\n",
    "        self.lambert_logeps = pd.read_csv(stem + \"lambert_1996_abundances.dat\")\n",
    "        # RES: ~23,000, FeII + photometric models, 3600-9000 A\n",
    "        \n",
    "        # Fe/H from Wallerstein and Huang 2010, arXiv 1004.2017\n",
    "        self.wallerstein_feh = pd.read_csv(stem + \"wallerstein_huang_2010_abundances.dat\")\n",
    "        # RES: ~30,000, FeII\n",
    "        \n",
    "        # Fe/H from Chadid+ 2017 ApJ 835.2:187 (FeI and II lines)\n",
    "        self.chadid_feh = pd.read_csv(stem + \"chadid_2017_abundances.dat\")\n",
    "        # RES: 38000, FeI & FeII, 3400-9900 A\n",
    "\n",
    "        # Fe/H from Liu+ 2013 Res Ast Astroph 13:1307\n",
    "        self.liu_feh = pd.read_csv(stem + \"liu_2013_abundances.dat\")\n",
    "        # RES: ~60,000, FeI (& FeII?), 5100-6400 A\n",
    "\n",
    "        # Fe/H from Nemec+ 2013\n",
    "        self.nemec_feh = pd.read_csv(stem + \"nemec_2013_abundances.dat\")\n",
    "        # RES: ~65,000 or 36,000, FeI & FeII, 5150-5200 A\n",
    "\n",
    "        # Fe/H from Fernley+ 1997\n",
    "        self.fernley97_feh = pd.read_csv(stem + \"fernley_1997_abundances.dat\")\n",
    "        # RES: 60,000, two FeII lines, 5900-8100 A\n",
    "\n",
    "        # Fe/H from Solano+ 1997\n",
    "        self.solano_feh = pd.read_csv(stem + \"solano_1997_abundances.dat\")\n",
    "        # RES: 22,000 & 19,000, strong FeI lines, 4160-4390 & 4070-4490 A\n",
    "        \n",
    "        # Fe/H from Pancino+ 2015 MNRAS 447:2404\n",
    "        self.pacino_feh = pd.read_csv(stem + \"pacino_2015_abundances.dat\") \n",
    "        # RES: >30,000, FeI (weighted average), 4000-8500 A\n",
    "\n",
    "        # Fe/H from Sneden+ 2017\n",
    "        self.sneden_feh = pd.read_csv(stem + \"sneden_2017_abundances.dat\")\n",
    "        # RES: ~27,000 (at 5000 A), FeI & FeII, 3400-9000 A\n",
    "        \n",
    "        # convert Lambert's values, which are in terms of log(eps)\n",
    "        # FeH = log(epsFe) - log(epsFe,sol)\n",
    "        #     = log(epsFe) - log(NFe,sol/NH,sol)\n",
    "        #     = log(epsFe) - 7.51 # value of 7.51 from Anstee+ 1997, MNRAS\n",
    "        self.lambert_logeps['feh'] = np.subtract(self.lambert_logeps['log_eps_fe_spec'], 7.51) \n",
    "        \n",
    "        # average the values in Chadid from FeI and FeII lines\n",
    "        self.chadid_feh['feh'] = np.mean([self.chadid_feh['fehI'].values,self.chadid_feh['fehII'].values],axis=0)\n",
    "        \n",
    "        ## ## INCLUDE SINGLE DATA PT FROM KOLENBERG+ 2010? (SEE CHADID+ 2017, FIG. 7)\n",
    "        \n",
    "        # FYI: average Fe/H values in Liu+ 2013 which were taken at different phases\n",
    "        # liu_feh.groupby(liu_feh['name'], axis=0, as_index=False).mean()\n",
    "        \n",
    "        # FYI: average Fe/H values in Sneden+ 1997 which were taken at different epochs\n",
    "        # sneden_feh.groupby(sneden_feh['name'], axis=0, as_index=False).mean()\n",
    "        \n",
    "        # Fe/H from Kemper+ 1982; this might serve as the common basis for RRcs\n",
    "        self.kemper_feh = pd.read_csv(stem + \"kemper_1982_abundances.dat\")\n",
    "\n",
    "        # Fe/H from Govea+ 2014\n",
    "        ## ## note: Govea+ has abundances for each phase value, and this includes NLTE phases; how to get single Fe/H?\n",
    "        self.govea_feh = pd.read_csv(stem + \"govea_2014_abundances.dat\")\n",
    "        \n",
    "\n",
    "        #####################\n",
    "        \n",
    "        # initialize arrays: essential info\n",
    "        empir_spec_name_array = []\n",
    "        star_name_array = []\n",
    "        H_data_array = []\n",
    "        K_data_array = []\n",
    "        err_H_data_array = [] \n",
    "        err_K_data_array = []\n",
    "\n",
    "        # initialize arrays: other info\n",
    "        Hbet_data_array = []\n",
    "        err_Hbet_data_array = []\n",
    "        Hgam_data_array = []\n",
    "        err_Hgam_data_array = []\n",
    "        rHgam_data_array = [] # rescaled Hgamma\n",
    "        err_rHgam_data_array = []\n",
    "        Hdel_data_array = []\n",
    "        err_Hdel_data_array = []\n",
    "        Heps_data_array = []\n",
    "        err_Heps_data_array = []\n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        # make a list of all unique EMPIRICAL spectrum names\n",
    "        uniqueSpecNames = line_data.drop_duplicates(subset='empir_spec_name')['empir_spec_name']\n",
    "\n",
    "    def matchmaker(self, input_table, basis_table, highres_dataset_name):\n",
    "        '''\n",
    "        Find what stars are common to two input tables, and return array of FeHs from the first table\n",
    "\n",
    "        INPUTS:\n",
    "        input_table: table I'm interested in checking for overlapping stars \n",
    "            (pandas dataframe with col ['name']: star name; col ['feh']: Fe/H)\n",
    "        basis_table: table with the names for which I am looking for repeats in the other table\n",
    "            (pandas dataframe with col ['name']: star name; col ['feh']: Fe/H)\n",
    "        highres_dataset_name: string indicating the name of the highres dataset\n",
    "\n",
    "        OUTPUTS:\n",
    "        pandas dataframe with\n",
    "        1. overlapping star names\n",
    "        2. FeHs from the input_table\n",
    "        3. FeHs from the basis_table\n",
    "        4. residuals in FeH: FeH_input - FeH_basis\n",
    "        5. string indicating the high-res dataset being matched\n",
    "        '''\n",
    "\n",
    "        self.input_table = input_table\n",
    "        self.basis_table = basis_table\n",
    "            \n",
    "        input_FeH = [] # Fe/H of high-res study\n",
    "        basis_FeH = [] # Fe/H of basis (ex. Layden 1994)\n",
    "        star_name_array = [] # name of star\n",
    "\n",
    "        for row in range(0,len(input_table)): # scan over each row in input table\n",
    "            if (basis_table['name'] == input_table['name'][row]).any():\n",
    "                input_FeH = np.append(input_FeH,input_table['feh'][row])\n",
    "                basis_FeH = np.append(basis_FeH,basis_table.loc[basis_table['name'] == input_table['name'][row]]['feh'])\n",
    "                star_name_array = np.append(star_name_array,input_table['name'][row])\n",
    "\n",
    "        d = dict()\n",
    "        d['name_star'] = star_name_array\n",
    "        d['FeH_highres'] = input_FeH\n",
    "        d['FeH_basis'] = basis_FeH\n",
    "        d['name_highres_dataset'] = np.repeat(highres_dataset_name, len(star_name_array))\n",
    "        d['name_basis_dataset'] = np.repeat(highres_dataset_name, len(star_name_array))\n",
    "        \n",
    "        df = pd.DataFrame(data=d)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-10-03d48b3d8599>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-03d48b3d8599>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class MetalBasisTypeSpecific(LitMetallicities):\n",
    "    '''\n",
    "    Class to make a metallicity basis specific to the subtype: RRab (default) or RRc\n",
    "    '''\n",
    "\n",
    "    def __init__(self, \n",
    "                 plot_name, \n",
    "                 star_type=\"RRab\"):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        plot_name: string for the plot file name\n",
    "        star_type: which RRL subtype to cross-match Fe/H values with a basis set\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        self.__plot_name = plot_name\n",
    "        self.__star_type = star_type\n",
    "        #self.__offset = offset\n",
    "        \n",
    "    def calc_FeH_program_stars(self):\n",
    "    '''\n",
    "    Calculate metallicities for the program stars which form the basis of the\n",
    "    metallicity calibration, by using the remapping relationships\n",
    "\n",
    "    INPUTS:\n",
    "    basis_set: basis set used for either RRab (such as Layden 1994) or RRc (such as Kemper+ 1982)\n",
    "    '''\n",
    "\n",
    "    # retrieve our own program stars and remap those of the right type\n",
    "    if self.__star_type == \"RRab\":\n",
    "        type_string = \"ab\"\n",
    "        basis_set = self.layden_feh\n",
    "        basis_string = \"Layden RRab basis set\" # string for plots\n",
    "    elif self.__star_type == \"RRc\":\n",
    "        type_string = \"c\"\n",
    "        basis_set = self.kemper_feh\n",
    "        basis_string = \"Kemper RRc basis set\"\n",
    "\n",
    "    # retrieve our stars here, and extract only those which conform to the right type\n",
    "    program_stars_subset = self.our_program_stars.loc[self.our_program_stars['type'] == type_string].reset_index()\n",
    "\n",
    "    # find matches with the basis set\n",
    "    program_stars_subset_matched = self.matchmaker(program_stars_subset, basis_set)\n",
    "\n",
    "    # find the coefficients we're interested in\n",
    "    map_info = self.make_basis()\n",
    "    print(map_info)\n",
    "\n",
    "    # remap metallicities via\n",
    "    # [Fe/H]_highres = m*[Fe/H]_basis_set + b   \n",
    "    program_stars_subset_matched['mapped_FeH'] = np.add(np.multiply(program_stars_subset_matched['basis_FeH'],\n",
    "                                                                    map_info['coeff_merged_highres'][0]),\n",
    "                                                        map_info['coeff_merged_highres'][1])\n",
    "\n",
    "    print(program_stars_subset_matched.keys())\n",
    "    # save a plot of calibration program stars Fe/H\n",
    "    # post-mapped Fe/H vs. pre-mapped (i.e., basis set) Fe/H\n",
    "    limits = [-3.0,0.5]\n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10,10))\n",
    "    axs.plot([limits[0],limits[1]],[limits[0],limits[1]], linestyle='--') # make 1-to-1 line\n",
    "    axs.scatter(program_stars_subset_matched['basis_FeH'], program_stars_subset_matched['mapped_FeH']) # input vs. basis\n",
    "    axs.set_xlim(limits[0], limits[1])\n",
    "    axs.set_ylabel(\"Fe/H, high-res\")\n",
    "    axs.set_xlabel(\"Fe/H, \"+basis_string)\n",
    "    #axs.set_title(\"m = \"+str(m_merged_highres)+\", b = \"+str(b_merged_highres))\n",
    "\n",
    "    fig.suptitle('Calculated Fe/H of calibration program stars\\n('+type_string+' subtype)')\n",
    "    #fig.tight_layout()\n",
    "    plt.savefig('calculated_FeH_'+self.__plot_name, overwrite=True)\n",
    "    plt.clf()\n",
    "\n",
    "    '''\n",
    "    # write out\n",
    "    convert_to_df = pd.DataFrame.from_dict(dict_our_program_stars['name']) # initialize\n",
    "    convert_to_df.columns = ['name'] # rename the column\n",
    "    convert_to_df['mapped_feh'] = pd.DataFrame.from_dict(dict_our_program_stars['mapped_feh']) # add the remapped Fe/H\n",
    "    no_return = convert_to_df.to_csv(write_loc + \"mapped_feh.csv\") # write out ## ## note 2 things: 1., this should be appeneded to our .csv with EWs; 2. there is no phase info here yet\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambert\n",
      "{'name': array(['DH Peg', 'T Sex'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.32, -1.56]), 'basis_FeH': array([-1.04, -1.18]), 'residuals_FeH': array([-0.28, -0.38])}\n",
      "nemec\n",
      "{'name': [], 'input_FeH': [], 'basis_FeH': [], 'residuals_FeH': array([], dtype=float64)}\n",
      "liu\n",
      "{'name': array(['DH Peg'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.09666667]), 'basis_FeH': array([-1.04]), 'residuals_FeH': array([-0.05666667])}\n",
      "chadid\n",
      "{'name': [], 'input_FeH': [], 'basis_FeH': [], 'residuals_FeH': array([], dtype=float64)}\n",
      "fernley\n",
      "{'name': array(['AE Boo', 'UY Cam', 'U Com', 'BX Leo', 'VZ Peg', 'AP Ser', 'T Sex',\n",
      "       'SX UMa'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.34, -1.51, -1.19, -1.21, -1.78, -1.43, -1.37, -1.45]), 'basis_FeH': array([-1.48, -1.06, -1.32, -1.23, -1.75, -1.37, -1.18, -1.82]), 'residuals_FeH': array([ 0.14, -0.45,  0.13,  0.02, -0.03, -0.06, -0.19,  0.37])}\n",
      "solano\n",
      "{'name': array(['BV Aqr', 'AE Boo', 'DH Peg', 'VZ Peg', 'AP Ser', 'T Sex', 'MT Tel',\n",
      "       'SX UMa'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.18, -1.18, -1.35, -1.63, -1.62, -1.27, -1.64, -1.63]), 'basis_FeH': array([-1.48, -1.48, -1.04, -1.75, -1.37, -1.18, -1.82, -1.82]), 'residuals_FeH': array([ 0.3 ,  0.3 , -0.31,  0.12, -0.25, -0.09,  0.18,  0.19])}\n",
      "wallerstein\n",
      "{'name': array(['DH Peg', 'RU Psc', 'RZ Cep'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.53, -2.04, -2.1 ]), 'basis_FeH': array([-1.04, -1.65, -1.48]), 'residuals_FeH': array([-0.49, -0.39, -0.62])}\n",
      "govea\n",
      "{'name': array(['YZ Cap'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.49428571]), 'basis_FeH': array([-1.29]), 'residuals_FeH': array([-0.20428571])}\n",
      "[{'name': array(['DH Peg', 'T Sex'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.32, -1.56]), 'basis_FeH': array([-1.04, -1.18]), 'residuals_FeH': array([-0.28, -0.38])}, {'name': [], 'input_FeH': [], 'basis_FeH': [], 'residuals_FeH': array([], dtype=float64)}, {'name': array(['DH Peg'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.09666667]), 'basis_FeH': array([-1.04]), 'residuals_FeH': array([-0.05666667])}, {'name': [], 'input_FeH': [], 'basis_FeH': [], 'residuals_FeH': array([], dtype=float64)}, {'name': array(['AE Boo', 'UY Cam', 'U Com', 'BX Leo', 'VZ Peg', 'AP Ser', 'T Sex',\n",
      "       'SX UMa'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.34, -1.51, -1.19, -1.21, -1.78, -1.43, -1.37, -1.45]), 'basis_FeH': array([-1.48, -1.06, -1.32, -1.23, -1.75, -1.37, -1.18, -1.82]), 'residuals_FeH': array([ 0.14, -0.45,  0.13,  0.02, -0.03, -0.06, -0.19,  0.37])}, {'name': array(['BV Aqr', 'AE Boo', 'DH Peg', 'VZ Peg', 'AP Ser', 'T Sex', 'MT Tel',\n",
      "       'SX UMa'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.18, -1.18, -1.35, -1.63, -1.62, -1.27, -1.64, -1.63]), 'basis_FeH': array([-1.48, -1.48, -1.04, -1.75, -1.37, -1.18, -1.82, -1.82]), 'residuals_FeH': array([ 0.3 ,  0.3 , -0.31,  0.12, -0.25, -0.09,  0.18,  0.19])}, {'name': array(['DH Peg', 'RU Psc', 'RZ Cep'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.53, -2.04, -2.1 ]), 'basis_FeH': array([-1.04, -1.65, -1.48]), 'residuals_FeH': array([-0.49, -0.39, -0.62])}, {'name': array(['YZ Cap'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.49428571]), 'basis_FeH': array([-1.29]), 'residuals_FeH': array([-0.20428571])}]\n",
      "{'input_FeH': array([-1.32      , -1.56      , -1.09666667, -1.34      , -1.51      ,\n",
      "       -1.19      , -1.21      , -1.78      , -1.43      , -1.37      ,\n",
      "       -1.45      , -1.18      , -1.18      , -1.35      , -1.63      ,\n",
      "       -1.62      , -1.27      , -1.64      , -1.63      , -1.53      ,\n",
      "       -2.04      , -2.1       , -1.49428571]), 'residuals': array([-0.28      , -0.38      , -0.05666667,  0.14      , -0.45      ,\n",
      "        0.13      ,  0.02      , -0.03      , -0.06      , -0.19      ,\n",
      "        0.37      ,  0.3       ,  0.3       , -0.31      ,  0.12      ,\n",
      "       -0.25      , -0.09      ,  0.18      ,  0.19      , -0.49      ,\n",
      "       -0.39      , -0.62      , -0.20428571]), 'basis_FeH': array([-1.04, -1.18, -1.04, -1.48, -1.06, -1.32, -1.23, -1.75, -1.37,\n",
      "       -1.18, -1.82, -1.48, -1.48, -1.04, -1.75, -1.37, -1.18, -1.82,\n",
      "       -1.82, -1.04, -1.65, -1.48, -1.29]), 'coeff_merged_highres': [0.43632009089288126, -0.87023613409548928], 'name': array(['DH Peg', 'T Sex', 'DH Peg', 'AE Boo', 'UY Cam', 'U Com', 'BX Leo',\n",
      "       'VZ Peg', 'AP Ser', 'T Sex', 'SX UMa', 'BV Aqr', 'AE Boo', 'DH Peg',\n",
      "       'VZ Peg', 'AP Ser', 'T Sex', 'MT Tel', 'SX UMa', 'DH Peg', 'RU Psc',\n",
      "       'RZ Cep', 'YZ Cap'],\n",
      "      dtype='<U32'), 'coeff_merged_resid': [-0.56367990910711896, -0.87023613409548928]}\n",
      "dict_keys(['name', 'input_FeH', 'mapped_FeH', 'basis_FeH', 'residuals_FeH'])\n"
     ]
    }
   ],
   "source": [
    "#test_rrab = MetalBasisTypeSpecific(plot_name='name_here',offset=True).calc_FeH_program_stars()\n",
    "test_rrc = MetalBasisTypeSpecific(plot_name='name_here',star_type=\"RRc\").calc_FeH_program_stars()\n",
    "\n",
    "#test_stuff = MetalBasisTypeSpecific(plot_name='name_here',star_type=\"RRc\").make_basis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'basis_FeH': array([-1.04, -1.18, -1.04, -1.48, -1.06, -1.32, -1.23, -1.75, -1.37,\n",
      "       -1.18, -1.82, -1.48, -1.48, -1.04, -1.75, -1.37, -1.18, -1.82,\n",
      "       -1.82, -1.04, -1.65, -1.48]), 'coeff_merged_highres': [0.43997057186033556, -0.86238029905352753], 'name': array(['DH Peg', 'T Sex', 'DH Peg', 'AE Boo', 'UY Cam', 'U Com', 'BX Leo',\n",
      "       'VZ Peg', 'AP Ser', 'T Sex', 'SX UMa', 'BV Aqr', 'AE Boo', 'DH Peg',\n",
      "       'VZ Peg', 'AP Ser', 'T Sex', 'MT Tel', 'SX UMa', 'DH Peg', 'RU Psc',\n",
      "       'RZ Cep'],\n",
      "      dtype='<U32'), 'residuals': array([-0.28      , -0.38      , -0.05666667,  0.14      , -0.45      ,\n",
      "        0.13      ,  0.02      , -0.03      , -0.06      , -0.19      ,\n",
      "        0.37      ,  0.3       ,  0.3       , -0.31      ,  0.12      ,\n",
      "       -0.25      , -0.09      ,  0.18      ,  0.19      , -0.49      ,\n",
      "       -0.39      , -0.62      ]), 'input_FeH': array([-1.32      , -1.56      , -1.09666667, -1.34      , -1.51      ,\n",
      "       -1.19      , -1.21      , -1.78      , -1.43      , -1.37      ,\n",
      "       -1.45      , -1.18      , -1.18      , -1.35      , -1.63      ,\n",
      "       -1.62      , -1.27      , -1.64      , -1.63      , -1.53      ,\n",
      "       -2.04      , -2.1       ]), 'coeff_merged_resid': [-0.56002942813966494, -0.86238029905352864]}\n"
     ]
    }
   ],
   "source": [
    "print(test_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MatchmakerLayden(LitMetallicities):\n",
    "\n",
    "        def __init__(self, plot_name, offset=False):\n",
    "                super().__init__()\n",
    "                self.__plot_name = plot_name\n",
    "\n",
    "        \n",
    "        def matchmaker(self, plot_name, offset=False):\n",
    "                '''\n",
    "                Find what stars overlap with Layden 1994, and return star name, FeH values, residuals\n",
    "                \n",
    "                The functionality of LitMetallicities is inherited, and we just add Chadid+ 17-style offsets, a best-fit line, and plotting functionality\n",
    "\n",
    "                INPUTS:\n",
    "                input_table: table of likely high-res-derived Fe/H values of RRabs, which I want to cross-ref with Layden 94\n",
    "                layden_table: the layden table, which serves as the basis set\n",
    "                plot_name: file name for saving a plot of the results\n",
    "\n",
    "                OUTPUTS:\n",
    "                dictionary with\n",
    "                1. overlapping star names\n",
    "                2. Fe/Hs from the input_table\n",
    "                3. Fe/Hs from Layden\n",
    "                '''\n",
    "    \n",
    "                # best-fit line\n",
    "                coeff = np.polyfit(laydenFeH, residuals, 1)\n",
    "                limits = [-3.0,0.5]\n",
    "                line = np.multiply(coeff[0],limits)+coeff[1]\n",
    "\n",
    "                ## ## IT APPEARS THE OFFSET FLAG IS DEPRECATED HERE?\n",
    "                # if there needs to be an offset (like in Fig. 6 of Chadid+ 2017)\n",
    "                chadid_y_125 = -0.10583621694962 # from Chadid line at Fe/H=-1.25\n",
    "                this_y_125 = np.multiply(coeff[0],-1.25)+coeff[1] # y-value of this line at Fe/H=-1.25\n",
    "                net_offset = chadid_y_125 - this_y_125 # offset needed to move line\n",
    "                print('Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:')\n",
    "                print(net_offset)\n",
    "                print('Number of overlapping stars:')\n",
    "                print(len(residuals))\n",
    "                line_offset = np.add(line,net_offset)\n",
    "    \n",
    "                # save a plot\n",
    "                '''\n",
    "                plt.scatter(laydenFeH, np.subtract(inputFeH,laydenFeH))\n",
    "                plt.plot([-3.0,0.5], [0., 0.], linestyle='--')\n",
    "                plt.plot(limits, line)\n",
    "                plt.plot(limits, line_offset)\n",
    "                #plt.xlim([-3.0,0.5])\n",
    "                #plt.ylim([-0.6,0.6])\n",
    "                plt.xlabel('[Fe/H]_Lay94')\n",
    "                plt.ylabel('[Fe/H]_input - [Fe/H]_Lay94')\n",
    "                plt.title('residuals between '+str(plot_name)+' and Lay94\\ny=mx+b, m='+str(coeff[0])+', b='+str(coeff[1])+'\\n offset '+str(net_offset))\n",
    "                plt.savefig(plot_name+'_test_180708.png')\n",
    "                #plt.show()\n",
    "                plt.clf()\n",
    "                '''\n",
    "            \n",
    "                # return \n",
    "                # 1. overlapping Layden94 values\n",
    "                # 2. FeH values from lit source\n",
    "                # 3. Residuals between 1. and 2. (see Chadid+ 2017 ApJ 835:187, Figs. 5, 6, 7)\n",
    "                # 4. coefficients of best-fit line\n",
    "                # 5. offset in y to bring lit FeH values to match Chadid+ 2017 at FeH=-1.25 (see Chadid+ 2017 Figs. 5, 6)\n",
    "                # 6. Residuals (from 3.) minus the offset (from 5.)  (see Chadid+ 2017 Fig. 7)\n",
    "                # 7. The names of the stars (in same order as arrays for 1., 2., 3., 4.)\n",
    "        \n",
    "                d = dict()\n",
    "                d['laydenFeH'] = laydenFeH\n",
    "                d['inputFeH'] = inputFeH\n",
    "                d['residuals'] = residuals\n",
    "                d['coeff'] = coeff\n",
    "                d['net_offset'] = net_offset # this needs to be ADDED to high-res study data to make it match Chadid\n",
    "                d['residuals_shifted'] = np.add(residuals,net_offset)\n",
    "                d['name'] = nameArray\n",
    "        \n",
    "                return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "junk = LitMetallicities()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
