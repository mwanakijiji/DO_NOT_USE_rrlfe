{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some functions that will be used in the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LitMetallicities():\n",
    "    '''\n",
    "    Class to \n",
    "    1.   read in Fe/H values from the literature \n",
    "    2.   initialize data set cross-referencing functionality\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        stem = \"./rrlyrae_metallicity/src/high_res_feh/\"\n",
    "\n",
    "        # stand-in that consists of our program star names\n",
    "        self.our_program_stars = pd.read_csv(stem + \"our_program_stars_names_only.csv\")\n",
    "        \n",
    "        # Fe/H from Layden+ 1994; this may serve as the common basis for RRabs\n",
    "        self.layden_feh = pd.read_csv(stem + \"layden_1994_abundances.dat\")\n",
    "        # RES: \"rather low\"\n",
    "        \n",
    "        # Fe/H Clementini+ 1995\n",
    "        self.clementini_feh = pd.read_csv(stem + \"clementini_1995_abundances.dat\")\n",
    "\n",
    "        # Fe/H Fernley+ 1996\n",
    "        self.fernley_feh = pd.read_csv(stem + \"fernley_1996_abundances.dat\")\n",
    "        # RES: 60,000, FeI & FeII, 5900-8100 A\n",
    "        \n",
    "        # log(eps) from Lambert+ 1996\n",
    "        self.lambert_logeps = pd.read_csv(stem + \"lambert_1996_abundances.dat\")\n",
    "        # RES: ~23,000, FeII + photometric models, 3600-9000 A\n",
    "        \n",
    "        # Fe/H from Wallerstein and Huang 2010, arXiv 1004.2017\n",
    "        self.wallerstein_feh = pd.read_csv(stem + \"wallerstein_huang_2010_abundances.dat\")\n",
    "        # RES: ~30,000, FeII\n",
    "        \n",
    "        # Fe/H from Chadid+ 2017 ApJ 835.2:187 (FeI and II lines)\n",
    "        self.chadid_feh = pd.read_csv(stem + \"chadid_2017_abundances.dat\")\n",
    "        # RES: 38000, FeI & FeII, 3400-9900 A\n",
    "\n",
    "        # Fe/H from Liu+ 2013 Res Ast Astroph 13:1307\n",
    "        self.liu_feh = pd.read_csv(stem + \"liu_2013_abundances.dat\")\n",
    "        # RES: ~60,000, FeI (& FeII?), 5100-6400 A\n",
    "\n",
    "        # Fe/H from Nemec+ 2013\n",
    "        self.nemec_feh = pd.read_csv(stem + \"nemec_2013_abundances.dat\")\n",
    "        # RES: ~65,000 or 36,000, FeI & FeII, 5150-5200 A\n",
    "\n",
    "        # Fe/H from Fernley+ 1997\n",
    "        self.fernley97_feh = pd.read_csv(stem + \"fernley_1997_abundances.dat\")\n",
    "        # RES: 60,000, two FeII lines, 5900-8100 A\n",
    "\n",
    "        # Fe/H from Solano+ 1997\n",
    "        self.solano_feh = pd.read_csv(stem + \"solano_1997_abundances.dat\")\n",
    "        # RES: 22,000 & 19,000, strong FeI lines, 4160-4390 & 4070-4490 A\n",
    "        \n",
    "        # Fe/H from Pancino+ 2015 MNRAS 447:2404\n",
    "        self.pacino_feh = pd.read_csv(stem + \"pacino_2015_abundances.dat\") \n",
    "        # RES: >30,000, FeI (weighted average), 4000-8500 A\n",
    "\n",
    "        # Fe/H from Sneden+ 2017\n",
    "        self.sneden_feh = pd.read_csv(stem + \"sneden_2017_abundances.dat\")\n",
    "        # RES: ~27,000 (at 5000 A), FeI & FeII, 3400-9000 A\n",
    "        \n",
    "        # convert Lambert's values, which are in terms of log(eps)\n",
    "        # FeH = log(epsFe) - log(epsFe,sol)\n",
    "        #     = log(epsFe) - log(NFe,sol/NH,sol)\n",
    "        #     = log(epsFe) - 7.51 # value of 7.51 from Anstee+ 1997, MNRAS\n",
    "        self.lambert_logeps['feh'] = np.subtract(self.lambert_logeps['log_eps_fe_spec'], 7.51) \n",
    "        \n",
    "        # average the values in Chadid from FeI and FeII lines\n",
    "        self.chadid_feh['feh'] = np.mean([self.chadid_feh['fehI'].values,self.chadid_feh['fehII'].values],axis=0)\n",
    "        \n",
    "        ## ## INCLUDE SINGLE DATA PT FROM KOLENBERG+ 2010? (SEE CHADID+ 2017, FIG. 7)\n",
    "        \n",
    "        # FYI: average Fe/H values in Liu+ 2013 which were taken at different phases\n",
    "        # liu_feh.groupby(liu_feh['name'], axis=0, as_index=False).mean()\n",
    "        \n",
    "        # FYI: average Fe/H values in Sneden+ 1997 which were taken at different epochs\n",
    "        # sneden_feh.groupby(sneden_feh['name'], axis=0, as_index=False).mean()\n",
    "        \n",
    "        # Fe/H from Kemper+ 1982; this might serve as the common basis for RRcs\n",
    "        self.kemper_feh = pd.read_csv(stem + \"kemper_1982_abundances.dat\")\n",
    "\n",
    "        # Fe/H from Govea+ 2014\n",
    "        ## ## note: Govea+ has abundances for each phase value, and this includes NLTE phases; how to get single Fe/H?\n",
    "        self.govea_feh = pd.read_csv(stem + \"govea_2014_abundances.dat\")\n",
    "        \n",
    "\n",
    "        #####################\n",
    "        \n",
    "        # initialize arrays: essential info\n",
    "        empir_spec_name_array = []\n",
    "        star_name_array = []\n",
    "        H_data_array = []\n",
    "        K_data_array = []\n",
    "        err_H_data_array = [] \n",
    "        err_K_data_array = []\n",
    "\n",
    "        # initialize arrays: other info\n",
    "        Hbet_data_array = []\n",
    "        err_Hbet_data_array = []\n",
    "        Hgam_data_array = []\n",
    "        err_Hgam_data_array = []\n",
    "        rHgam_data_array = [] # rescaled Hgamma\n",
    "        err_rHgam_data_array = []\n",
    "        Hdel_data_array = []\n",
    "        err_Hdel_data_array = []\n",
    "        Heps_data_array = []\n",
    "        err_Heps_data_array = []\n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        # make a list of all unique EMPIRICAL spectrum names\n",
    "        uniqueSpecNames = line_data.drop_duplicates(subset='empir_spec_name')['empir_spec_name']\n",
    "\n",
    "    def matchmaker(self, input_table, basis_table, highres_dataset_name):\n",
    "        '''\n",
    "        Find what stars are common to two input tables, and return array of FeHs from the first table\n",
    "\n",
    "        INPUTS:\n",
    "        input_table: table I'm interested in checking for overlapping stars \n",
    "            (pandas dataframe with col ['name']: star name; col ['feh']: Fe/H)\n",
    "        basis_table: table with the names for which I am looking for repeats in the other table\n",
    "            (pandas dataframe with col ['name']: star name; col ['feh']: Fe/H)\n",
    "        highres_dataset_name: string indicating the name of the highres dataset\n",
    "\n",
    "        OUTPUTS:\n",
    "        pandas dataframe with\n",
    "        1. overlapping star names\n",
    "        2. FeHs from the input_table\n",
    "        3. FeHs from the basis_table\n",
    "        4. residuals in FeH: FeH_input - FeH_basis\n",
    "        5. string indicating the high-res dataset being matched\n",
    "        '''\n",
    "\n",
    "        self.input_table = input_table\n",
    "        self.basis_table = basis_table\n",
    "            \n",
    "        input_FeH = [] # Fe/H of high-res study\n",
    "        basis_FeH = [] # Fe/H of basis (ex. Layden 1994)\n",
    "        star_name_array = [] # name of star\n",
    "\n",
    "        for row in range(0,len(input_table)): # scan over each row in input table\n",
    "            if (basis_table['name'] == input_table['name'][row]).any():\n",
    "                input_FeH = np.append(input_FeH,input_table['feh'][row])\n",
    "                basis_FeH = np.append(basis_FeH,basis_table.loc[basis_table['name'] == input_table['name'][row]]['feh'])\n",
    "                star_name_array = np.append(star_name_array,input_table['name'][row])\n",
    "\n",
    "        d = dict()\n",
    "        d['name_star'] = star_name_array\n",
    "        d['FeH_highres'] = input_FeH\n",
    "        d['FeH_basis'] = basis_FeH\n",
    "        d['name_highres_dataset'] = np.repeat(highres_dataset_name, len(star_name_array))\n",
    "        d['name_basis_dataset'] = np.repeat(highres_dataset_name, len(star_name_array))\n",
    "        \n",
    "        df = pd.DataFrame(data=d)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def match_highres_w_basis(self, star_type):\n",
    "        '''\n",
    "        Find what stars overlap with basis data set, and return star name, data set names, FeH values, residuals\n",
    "\n",
    "        The functionality of LitMetallicities is inherited\n",
    "        N.b. There are no offsets applied yet (as are applied in Chadid+ 2017 plots)\n",
    "\n",
    "        INPUTS:\n",
    "        input_table: table of high-res-derived Fe/H values, which I want to cross-ref with a basis (like Layden 94 or Kemper 82)\n",
    "        basis_table: the table which serves as the basis set\n",
    "        plot_name: file name for saving a plot of the results\n",
    "\n",
    "        OUTPUTS:\n",
    "        df: concatenated frames containing \n",
    "        ['name_star']: star_name_array\n",
    "        ['FeH_highres']: Fe/H from high-res study\n",
    "        ['FeH_basis']: Fe/H from basis set\n",
    "        ['name_highres_dataset']: string indicating the high-res dataset\n",
    "        ['name_basis_dataset']: string indicating the basis set\n",
    "        '''\n",
    "\n",
    "        # define the basis data set (like Layden 1994 for RRabs, or Kemper+ 1982 for RRcs)\n",
    "        if star_type == \"RRab\":\n",
    "            type_string = \"ab\"\n",
    "            basis_set = self.layden_feh\n",
    "            basis_string = \"Layden RRab basis set\" # string for plots\n",
    "        elif star_type == \"RRc\":\n",
    "            type_string = \"c\"\n",
    "            basis_set = self.kemper_feh\n",
    "            basis_string = \"Kemper RRc basis set\"\n",
    "        else:\n",
    "            sys.exit(\"Error! No RR Lyrae subtype chosen.\")\n",
    "\n",
    "\n",
    "        ## match ALL available high-res studies with the basis set\n",
    "\n",
    "        pd_Lambert_1996 = self.matchmaker(self.lambert_logeps, \n",
    "                                          basis_set, \n",
    "                                          highres_dataset_name=\"lambert_1996\") # Lambert+ 1996 (logeps has already been converted to Fe/H)\n",
    "        pd_Nemec_2013 = self.matchmaker(self.nemec_feh, \n",
    "                                        basis_set,\n",
    "                                        highres_dataset_name=\"nemec_2013\") # Nemec+ 2013\n",
    "        pd_Chadid_2017 = self.matchmaker(self.chadid_feh, \n",
    "                                         basis_set,\n",
    "                                         highres_dataset_name=\"chadid_2017\") # Chadid+ 2017\n",
    "        pd_Fernley_1997 = self.matchmaker(self.fernley97_feh, \n",
    "                                          basis_set,\n",
    "                                          highres_dataset_name=\"fernley_1997\") # Fernley+ 1997\n",
    "        pd_Solano_1997 = self.matchmaker(self.solano_feh, \n",
    "                                         basis_set,\n",
    "                                         highres_dataset_name=\"solano_1997\") # Solano+ 1997\n",
    "        pd_Wallerstein_2010 = self.matchmaker(self.wallerstein_feh, \n",
    "                                              basis_set,\n",
    "                                              highres_dataset_name=\"wallerstein_2010\") # Wallerstein 2010\n",
    "\n",
    "        # for Liu+ 2013, we need to group multiple Fe/H values by star name\n",
    "        # (the grouping is done here rather than further up because a bug causes the grouped column to disappear)\n",
    "        self.liu_feh_grouped = self.liu_feh.groupby(self.liu_feh[\"name\"], axis=0, as_index=False).mean()\n",
    "        pd_Liu_2013 = self.matchmaker(self.liu_feh_grouped, \n",
    "                                      basis_set,\n",
    "                                      highres_dataset_name=\"liu_2013\") # Liu+ 2013\n",
    "\n",
    "        # for Govea+ 2014, we need to group multiple Fe/H_I and Fe/H_II values by star name\n",
    "        # (the grouping is done here rather than further upstream because otherwise a bug causes \n",
    "        # the grouped column to disappear)\n",
    "        self.govea_feh_grouped = self.govea_feh.groupby(self.govea_feh[\"name\"], axis=0, as_index=False).mean()\n",
    "        # now, average the Fe/H_I and Fe/H_II values to get single Fe/H values\n",
    "        self.govea_feh_grouped[\"feh\"] = self.govea_feh_grouped[[\"feIh\",\"feIIh\"]].mean(axis=1)\n",
    "        pd_Govea_2014 = self.matchmaker(self.govea_feh_grouped, \n",
    "                                        basis_set,\n",
    "                                        highres_dataset_name=\"govea_2014\") # Govea+ 2014\n",
    "\n",
    "        # merge dataframes\n",
    "        pd_collected = [pd_Lambert_1996, pd_Nemec_2013, pd_Liu_2013, pd_Chadid_2017,\n",
    "                        pd_Fernley_1997, pd_Solano_1997, pd_Wallerstein_2010, pd_Govea_2014]\n",
    "        df = pd.concat(pd_collected).reset_index()\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def match_highres_w_basis(star_type):\n",
    "    '''\n",
    "    Find what stars overlap with basis data set, and return star name, data set names, FeH values, residuals\n",
    "\n",
    "    The functionality of LitMetallicities is inherited\n",
    "    N.b. There are no offsets applied yet (as are applied in Chadid+ 2017 plots)\n",
    "\n",
    "    INPUTS:\n",
    "    input_table: table of high-res-derived Fe/H values, which I want to cross-ref with a basis (like Layden 94 or Kemper 82)\n",
    "    basis_table: the table which serves as the basis set\n",
    "    plot_name: file name for saving a plot of the results\n",
    "\n",
    "    OUTPUTS:\n",
    "    df: concatenated frames containing \n",
    "    ['name_star']: star_name_array\n",
    "    ['FeH_highres']: Fe/H from high-res study\n",
    "    ['FeH_basis']: Fe/H from basis set\n",
    "    ['name_highres_dataset']: string indicating the high-res dataset\n",
    "    ['name_basis_dataset']: string indicating the basis set\n",
    "    '''\n",
    "\n",
    "    # define the basis data set (like Layden 1994 for RRabs, or Kemper+ 1982 for RRcs)\n",
    "    if star_type == \"RRab\":\n",
    "        type_string = \"ab\"\n",
    "        basis_set = self.layden_feh\n",
    "        basis_string = \"Layden RRab basis set\" # string for plots\n",
    "    elif star_type == \"RRc\":\n",
    "        type_string = \"c\"\n",
    "        basis_set = self.kemper_feh\n",
    "        basis_string = \"Kemper RRc basis set\"\n",
    "    else:\n",
    "        sys.exit(\"Error! No RR Lyrae subtype chosen.\")\n",
    "\n",
    "\n",
    "    ## match ALL available high-res studies with the basis set\n",
    "\n",
    "    pd_Lambert_1996 = self.matchmaker(self.lambert_logeps, \n",
    "                                      basis_set, \n",
    "                                      highres_dataset_name=\"lambert_1996\") # Lambert+ 1996 (logeps has already been converted to Fe/H)\n",
    "    pd_Nemec_2013 = self.matchmaker(self.nemec_feh, \n",
    "                                    basis_set,\n",
    "                                    highres_dataset_name=\"nemec_2013\") # Nemec+ 2013\n",
    "    pd_Chadid_2017 = self.matchmaker(self.chadid_feh, \n",
    "                                     basis_set,\n",
    "                                     highres_dataset_name=\"chadid_2017\") # Chadid+ 2017\n",
    "    pd_Fernley_1997 = self.matchmaker(self.fernley97_feh, \n",
    "                                      basis_set,\n",
    "                                      highres_dataset_name=\"fernley_1997\") # Fernley+ 1997\n",
    "    pd_Solano_1997 = self.matchmaker(self.solano_feh, \n",
    "                                     basis_set,\n",
    "                                     highres_dataset_name=\"solano_1997\") # Solano+ 1997\n",
    "    pd_Wallerstein_2010 = self.matchmaker(self.wallerstein_feh, \n",
    "                                          basis_set,\n",
    "                                          highres_dataset_name=\"wallerstein_2010\") # Wallerstein 2010\n",
    "\n",
    "    # for Liu+ 2013, we need to group multiple Fe/H values by star name\n",
    "    # (the grouping is done here rather than further up because a bug causes the grouped column to disappear)\n",
    "    self.liu_feh_grouped = self.liu_feh.groupby(self.liu_feh[\"name\"], axis=0, as_index=False).mean()\n",
    "    pd_Liu_2013 = self.matchmaker(self.liu_feh_grouped, \n",
    "                                  basis_set,\n",
    "                                  highres_dataset_name=\"liu_2013\") # Liu+ 2013\n",
    "\n",
    "    # for Govea+ 2014, we need to group multiple Fe/H_I and Fe/H_II values by star name\n",
    "    # (the grouping is done here rather than further upstream because otherwise a bug causes \n",
    "    # the grouped column to disappear)\n",
    "    self.govea_feh_grouped = self.govea_feh.groupby(self.govea_feh[\"name\"], axis=0, as_index=False).mean()\n",
    "    # now, average the Fe/H_I and Fe/H_II values to get single Fe/H values\n",
    "    self.govea_feh_grouped[\"feh\"] = self.govea_feh_grouped[[\"feIh\",\"feIIh\"]].mean(axis=1)\n",
    "    pd_Govea_2014 = self.matchmaker(self.govea_feh_grouped, \n",
    "                                    basis_set,\n",
    "                                    highres_dataset_name=\"govea_2014\") # Govea+ 2014\n",
    "\n",
    "    # merge dataframes\n",
    "    pd_collected = [pd_Lambert_1996, pd_Nemec_2013, pd_Liu_2013, pd_Chadid_2017,\n",
    "                    pd_Fernley_1997, pd_Solano_1997, pd_Wallerstein_2010, pd_Govea_2014]\n",
    "    df = pd.concat(pd_collected).reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_offsets(data_postmatch, chadid_offset=True):\n",
    "    '''\n",
    "    Fit linear regression to input high-res Fe/H and the basis set,\n",
    "    and find offset for each dataset to match some constant\n",
    "    \n",
    "    INPUTS:\n",
    "    data_postmatch: output from match_w_highres_basis(), containing\n",
    "        Fe/H data from high-res studies and basis set\n",
    "        \n",
    "    OUTPUTS:\n",
    "    df: dataframe containing\n",
    "    ['name_highres_dataset']: name indicating high-res study\n",
    "    ['offset_highres_dataset_residuals']: offset for the entire high-res \n",
    "        dataset, which needs to be applied to the vector (FeH_highres-FeH_basis)\n",
    "    '''\n",
    "    \n",
    "    # initialize dataframe\n",
    "    col_names =  [\"name_highres\", \"offset_highres_residuals\"]\n",
    "    df_offsets  = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    # loop over each high-res dataset\n",
    "    highres_names = data_postmatch[\"name_highres_dataset\"].unique() # names of high-res datasets\n",
    "    index_counter = 0 # initialize this for appending dataframes\n",
    "    for dataset_num in range(0,len(highres_names)):\n",
    "        \n",
    "        this_dataset_name = highres_names[dataset_num] # name of this dataset\n",
    "        this_dataset = data_postmatch[data_postmatch[\"name_highres_dataset\"].str.match(this_dataset_name)]\n",
    "    \n",
    "        # need at least 3 data points\n",
    "        if (len(this_dataset[\"FeH_highres\"]) > 2): \n",
    "    \n",
    "            # find linear regression of residuals\n",
    "            coeff = np.polyfit(this_dataset[\"FeH_basis\"],\n",
    "                               np.subtract(this_dataset[\"FeH_highres\"],\n",
    "                                           this_dataset[\"FeH_basis\"]),1)\n",
    "            limits = [-3.0,0.5] # Fe/H limits to display\n",
    "            line = np.multiply(coeff[0],limits)+coeff[1] # points to plot linear regression\n",
    "\n",
    "            # find offset between residuals and Chadid+ 2017 at Fe/H=-1.25 (see their Fig. 6)\n",
    "            if chadid_offset: \n",
    "                chadid_y_125 = -0.10583621694962 # from Chadid line at Fe/H=-1.25\n",
    "                FeH_resid_to_peg = chadid_y_125 # peg the FeH residuals to this y- point\n",
    "                FeH_basis_loc = -1.25 # corresponding x- value (Fe/H in the basis dataset)\n",
    "            else: \n",
    "                FeH_resid_to_peg = 0. # peg the data at this y- point\n",
    "                FeH_basis_loc = 0. # location in the basis dataset \n",
    "                print(\"Offset corresponds to (0,0)!\")\n",
    "\n",
    "            # y-value of the unshifted linear regression line at Fe/H=-1.25\n",
    "            this_y_125 = np.multiply(coeff[0],FeH_basis_loc)+coeff[1] \n",
    "\n",
    "            # offset to shift the linear regression line of the residuals to FeH_resid_to_peg\n",
    "            net_offset = chadid_y_125 - this_y_125\n",
    "\n",
    "            # line_offset = np.add(line,net_offset)\n",
    "\n",
    "            print('-----------------')\n",
    "            print('Calculating offsets for dataset '+this_dataset_name)\n",
    "            print('Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:')\n",
    "            print(net_offset)\n",
    "            print('Number of overlapping stars:')\n",
    "            print(len(this_dataset[\"FeH_basis\"]))\n",
    "\n",
    "            # append name of dataset and its offset to array\n",
    "            dict_this = {\"name_highres\":[this_dataset_name],\n",
    "                         \"offset_highres_residuals\":[net_offset]}\n",
    "            #print(pd.DataFrame(dict_this, index=[dataset_num]))\n",
    "            \n",
    "            # append info from this dataset\n",
    "            print(dict_this)\n",
    "            print(list(dict_this.items()))\n",
    "            print(pd.DataFrame(dict_this))\n",
    "            df_offsets = df_offsets.append(pd.DataFrame(dict_this)) \n",
    "            index_counter += 1 # increase the counter\n",
    "            \n",
    "        elif (len(this_dataset[\"FeH_highres\"]) <= 2): \n",
    "            \n",
    "            '''\n",
    "            # put in NaN offset\n",
    "            dict_this = {\"name_highres\": this_dataset_name,\n",
    "                         \"offset_highres_residuals\": np.nan}\n",
    "            #print(pd.DataFrame(dict_this, index=[dataset_num]))\n",
    "            \n",
    "            # append info from this dataset\n",
    "            df_offsets = df_offsets.append(pd.DataFrame(dict_this)) \n",
    "            \n",
    "            index_counter += 1 # increase the counter\n",
    "            '''\n",
    "            pass\n",
    " \n",
    "    return df_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_basis_via_offsets(df_to_offset,df_offsets):\n",
    "    '''\n",
    "    Apply offsets (which may be from RRabs, RRcs, combo, etc.) to data to make a basis\n",
    "\n",
    "    INPUTS:\n",
    "    df_to_offset: dataframe containing Fe/H values which we want to find residuals for, offset, and map\n",
    "        ['name_star']: star name\n",
    "        ['FeH_highres']: Fe/H from high-res study\n",
    "        ['FeH_basis']: Fe/H from basis set\n",
    "        ['name_highres_dataset']: string indicating the high-res dataset\n",
    "        ['name_basis_dataset']: string indicating the basis set\n",
    "          \n",
    "    df_offsets: dataframe containing the offset values and high-res dataset names\n",
    "        ['name_highres_dataset']: name indicating high-res study\n",
    "        ['offset_highres_dataset_residuals']: offset value to add to Fe/H values\n",
    "    '''\n",
    "\n",
    "    dict_merged_this_basis = {} # initialize dictionaries\n",
    "    dict_not_merged_this_basis = {}\n",
    "    highres_names = df_to_offset[\"name_highres_dataset\"].unique() # names of high-res datasets (which will also be the keys to dict_merged_this_basis)\n",
    "    \n",
    "    # for each high-res dataset name, apply the offsets to Fe/H residuals\n",
    "    for this_dataset_name in highres_names:    \n",
    "        \n",
    "        this_dataset = df_to_offset[df_to_offset[\"name_highres_dataset\"].str.match(this_dataset_name)]\n",
    "        \n",
    "        #print('this_resid_offset')\n",
    "        #print(df_offsets['offset_highres_residuals'].loc[df_offsets['name_highres'] == this_dataset_name].values)\n",
    "        \n",
    "        # retrieve the required offset\n",
    "        this_resid_offset = df_offsets['offset_highres_residuals'].loc[df_offsets['name_highres'] == this_dataset_name].values\n",
    "        if this_resid_offset: # if there is an offset that could be found for this dataset\n",
    "        \n",
    "            this_dataset[\"residuals_no_shift\"] = np.subtract(this_dataset[\"FeH_highres\"],this_dataset[\"FeH_basis\"])\n",
    "            this_dataset[\"residuals_shifted\"] = np.add(this_dataset[\"residuals_no_shift\"],this_resid_offset)\n",
    "\n",
    "            # add dataframe to dictionary; \n",
    "            # each key corresponds to a high-res dataset, and each value is a dataframe (this is good for plotting)\n",
    "            dict_not_merged_this_basis[this_dataset_name] = this_dataset\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "     \n",
    "    # merge [\"residuals_shifted\"] and [\"FeH_highres\"] across all \n",
    "    # dataframes in the dictionary (this is good for finding net Fe/H mapping)\n",
    "    pd_merged = pd.concat(dict_not_merged_this_basis.values(), ignore_index=True)\n",
    "    \n",
    "    # find best-fit line to Fe/H plot of high_res vs. basis \n",
    "    # (note that user may have used a flag to make Fe/H values be offset)\n",
    "    limits = [-3.0,0.5] # Fe/H limits to display\n",
    "    \n",
    "    m_merged_highres, b_merged_highres = np.polyfit(pd_merged[\"FeH_basis\"], pd_merged[\"FeH_highres\"], 1)\n",
    "    line_highres = np.multiply(m_merged_highres,limits)+b_merged_highres # make best-fit line for high-res Fe/H\n",
    "    \n",
    "    m_merged_shifted_resid, b_merged_shifted_resid = np.polyfit(pd_merged[\"FeH_basis\"], pd_merged[\"residuals_shifted\"], 1)\n",
    "    line_shifted_resid = np.multiply(m_merged_shifted_resid,limits)+b_merged_shifted_resid # make best-fit line for residuals\n",
    "\n",
    "    # save a plot (high_res vs. basis on top; residuals vs. basis on bottom)\n",
    "    '''\n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10,10), sharex=True)\n",
    "    axs[0].plot([limits[0],limits[1]],[limits[0],limits[1]], linestyle='--') # make 1-to-1 line\n",
    "    axs[0].plot([limits[0],limits[1]],np.add(np.multiply(m_merged_highres,[limits[0],limits[1]]),b_merged_highres), linestyle='--') # best-fit line\n",
    "    axs[0].scatter(basis_data_merged, highres_data_merged) # input vs. basis\n",
    "    axs[0].set_xlim(limits[0], limits[1])\n",
    "    axs[0].set_ylabel(\"Fe/H, high-res\")\n",
    "    axs[0].set_title(\"m = \"+str(m_merged_highres)+\", b = \"+str(b_merged_highres)+\"; (blue line: 1-to-1; orange line: best fit)\")\n",
    "    axs[1].axhline(y=0, linestyle='--') # dashed line at y=0\n",
    "    axs[1].scatter(basis_data_merged, residuals_data_merged) # input vs. basis\n",
    "    axs[1].set_xlabel(\"Fe/H, \"+basis_string)\n",
    "    axs[1].set_ylabel('Fe/H Residuals: high-res minus basis set')\n",
    "    axs[1].set_title(\"m = \"+str(m_merged_resid)+\", b = \"+str(b_merged_resid)+\"; (blue line: zero)\")\n",
    "    fig.suptitle(\"Finding remapping relation between\\nhigh-res studies and basis dataset\\n(\"+type_string+\" subtype)\")\n",
    "    #fig.tight_layout()\n",
    "    plt.savefig(\"remapping_\"+self.__plot_name, overwrite=True)\n",
    "    plt.clf()\n",
    "    d['coeff_merged_highres'] = [m_merged_highres, b_merged_highres] # best-fit line coeffs for high-res vs. basis \n",
    "    d['coeff_merged_resid'] = [m_merged_resid, b_merged_resid] # best-fit line coeffs for (residuals: high-res minus basis) vs. basis \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MetalBasisTypeSpecific(LitMetallicities):\n",
    "    '''\n",
    "    Class to make metallicity bases specific to subtypes: RRab, RRc\n",
    "    '''\n",
    "\n",
    "    def __init__(self, \n",
    "                 plot_name):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        plot_name: string for the plot file name\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        self.__plot_name = plot_name\n",
    "        #self.__star_type = star_type\n",
    "        #self.__offset = offset\n",
    "        \n",
    "        \n",
    "    def calc_FeH_program_stars(self):\n",
    "        '''\n",
    "        Calculate metallicities for the program stars which form the basis of the\n",
    "        metallicity calibration, by using the remapping relationships\n",
    "\n",
    "        INPUTS:\n",
    "        basis_set: basis set used for either RRab (such as Layden 1994) or RRc (such as Kemper+ 1982)\n",
    "        '''\n",
    "        \n",
    "        # match the RRab, RRcs stars with their basis sets\n",
    "        rrab_matches = self.match_highres_w_basis(\"RRab\")\n",
    "        rrc_matches = self.match_highres_w_basis(\"RRc\")\n",
    "    \n",
    "        # find necessary offsets to FeH_highres-FeH_basis\n",
    "        print(\"======= STEP 1 ========\")\n",
    "        rrab_offsets = return_offsets(rrab_matches)\n",
    "        print('--ha--')\n",
    "        print(rrab_offsets)\n",
    "        print(\"======= STEP 2 ========\")\n",
    "        rrc_offsets = return_offsets(rrc_matches)\n",
    "        print('-_-ha-_-')\n",
    "        print(rrc_offsets)\n",
    "        \n",
    "        # finally make the basess based on the found offsets\n",
    "        print(\"======= STEP 3 ========\")\n",
    "        rrab_basis_w_rrab_offsets = make_basis_via_offsets(rrab_matches,rrab_offsets)\n",
    "        print(\"======= STEP 4 ========\")\n",
    "        rrab_basis_w_rrc_offsets = make_basis_via_offsets(rrab_matches,rrc_offsets)\n",
    "        print(\"======= STEP 5 ========\")\n",
    "        rrc_basis_w_rrc_offsets = make_basis_via_offsets(rrc_matches,rrc_offsets)\n",
    "        print(\"======= STEP 6 ========\")\n",
    "        rrc_basis_w_rrab_offsets = make_basis_via_offsets(rrc_matches,rrab_offsets)\n",
    "\n",
    "        # mapping of FeH (IS THE BELOW CORRECT?) via\n",
    "        # [Fe/H]_highres = m*[Fe/H]_basis_set + b   \n",
    "        '''\n",
    "        program_stars_subset_matched['mapped_FeH'] = np.add(np.multiply(program_stars_subset_matched['basis_FeH'],\n",
    "                                                                    map_info['coeff_merged_highres'][0]),\n",
    "                                                        map_info['coeff_merged_highres'][1])\n",
    "        '''\n",
    "\n",
    "        # save a plot of calibration program stars Fe/H\n",
    "        # post-mapped Fe/H vs. pre-mapped (i.e., basis set) Fe/H\n",
    "        '''\n",
    "        limits = [-3.0,0.5]\n",
    "        plt.clf()\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(10,10))\n",
    "        axs.plot([limits[0],limits[1]],[limits[0],limits[1]], linestyle='--') # make 1-to-1 line\n",
    "        axs.scatter(program_stars_subset_matched['basis_FeH'], program_stars_subset_matched['mapped_FeH']) # input vs. basis\n",
    "        axs.set_xlim(limits[0], limits[1])\n",
    "        axs.set_ylabel(\"Fe/H, high-res\")\n",
    "        axs.set_xlabel(\"Fe/H, \"+basis_string)\n",
    "        #axs.set_title(\"m = \"+str(m_merged_highres)+\", b = \"+str(b_merged_highres))\n",
    "\n",
    "        fig.suptitle('Calculated Fe/H of calibration program stars\\n('+type_string+' subtype)')\n",
    "        #fig.tight_layout()\n",
    "        plt.savefig('calculated_FeH_'+self.__plot_name, overwrite=True)\n",
    "        plt.clf()\n",
    "\n",
    "        # write out\n",
    "        convert_to_df = pd.DataFrame.from_dict(dict_our_program_stars['name']) # initialize\n",
    "        convert_to_df.columns = ['name'] # rename the column\n",
    "        convert_to_df['mapped_feh'] = pd.DataFrame.from_dict(dict_our_program_stars['mapped_feh']) # add the remapped Fe/H\n",
    "        no_return = convert_to_df.to_csv(write_loc + \"mapped_feh.csv\") # write out ## ## note 2 things: 1., this should be appeneded to our .csv with EWs; 2. there is no phase info here yet\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= STEP 1 ========\n",
      "-----------------\n",
      "Calculating offsets for dataset lambert_1996\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "-0.09526329009940923\n",
      "Number of overlapping stars:\n",
      "14\n",
      "{'offset_highres_residuals': [-0.09526329009940923], 'name_highres': ['lambert_1996']}\n",
      "[('offset_highres_residuals', [-0.09526329009940923]), ('name_highres', ['lambert_1996'])]\n",
      "   name_highres  offset_highres_residuals\n",
      "0  lambert_1996                 -0.095263\n",
      "-----------------\n",
      "Calculating offsets for dataset nemec_2013\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "-0.33561597402175003\n",
      "Number of overlapping stars:\n",
      "10\n",
      "{'offset_highres_residuals': [-0.33561597402175003], 'name_highres': ['nemec_2013']}\n",
      "[('offset_highres_residuals', [-0.33561597402175003]), ('name_highres', ['nemec_2013'])]\n",
      "  name_highres  offset_highres_residuals\n",
      "0   nemec_2013                 -0.335616\n",
      "-----------------\n",
      "Calculating offsets for dataset liu_2013\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "-0.2295759734764461\n",
      "Number of overlapping stars:\n",
      "19\n",
      "{'offset_highres_residuals': [-0.2295759734764461], 'name_highres': ['liu_2013']}\n",
      "[('offset_highres_residuals', [-0.2295759734764461]), ('name_highres', ['liu_2013'])]\n",
      "  name_highres  offset_highres_residuals\n",
      "0     liu_2013                 -0.229576\n",
      "-----------------\n",
      "Calculating offsets for dataset chadid_2017\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "-2.868538739875248e-14\n",
      "Number of overlapping stars:\n",
      "26\n",
      "{'offset_highres_residuals': [-2.868538739875248e-14], 'name_highres': ['chadid_2017']}\n",
      "[('offset_highres_residuals', [-2.868538739875248e-14]), ('name_highres', ['chadid_2017'])]\n",
      "  name_highres  offset_highres_residuals\n",
      "0  chadid_2017             -2.868539e-14\n",
      "-----------------\n",
      "Calculating offsets for dataset fernley_1997\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "-0.37869913508179565\n",
      "Number of overlapping stars:\n",
      "31\n",
      "{'offset_highres_residuals': [-0.37869913508179565], 'name_highres': ['fernley_1997']}\n",
      "[('offset_highres_residuals', [-0.37869913508179565]), ('name_highres', ['fernley_1997'])]\n",
      "   name_highres  offset_highres_residuals\n",
      "0  fernley_1997                 -0.378699\n",
      "-----------------\n",
      "Calculating offsets for dataset solano_1997\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "-0.28112947278810496\n",
      "Number of overlapping stars:\n",
      "16\n",
      "{'offset_highres_residuals': [-0.28112947278810496], 'name_highres': ['solano_1997']}\n",
      "[('offset_highres_residuals', [-0.28112947278810496]), ('name_highres', ['solano_1997'])]\n",
      "  name_highres  offset_highres_residuals\n",
      "0  solano_1997                 -0.281129\n",
      "-----------------\n",
      "Calculating offsets for dataset wallerstein_2010\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "-0.14367587526014527\n",
      "Number of overlapping stars:\n",
      "19\n",
      "{'offset_highres_residuals': [-0.14367587526014527], 'name_highres': ['wallerstein_2010']}\n",
      "[('offset_highres_residuals', [-0.14367587526014527]), ('name_highres', ['wallerstein_2010'])]\n",
      "       name_highres  offset_highres_residuals\n",
      "0  wallerstein_2010                 -0.143676\n",
      "--ha--\n",
      "       name_highres  offset_highres_residuals\n",
      "0      lambert_1996             -9.526329e-02\n",
      "0        nemec_2013             -3.356160e-01\n",
      "0          liu_2013             -2.295760e-01\n",
      "0       chadid_2017             -2.868539e-14\n",
      "0      fernley_1997             -3.786991e-01\n",
      "0       solano_1997             -2.811295e-01\n",
      "0  wallerstein_2010             -1.436759e-01\n",
      "======= STEP 2 ========\n",
      "-----------------\n",
      "Calculating offsets for dataset fernley_1997\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "0.004344301856482685\n",
      "Number of overlapping stars:\n",
      "8\n",
      "{'offset_highres_residuals': [0.004344301856482685], 'name_highres': ['fernley_1997']}\n",
      "[('offset_highres_residuals', [0.004344301856482685]), ('name_highres', ['fernley_1997'])]\n",
      "   name_highres  offset_highres_residuals\n",
      "0  fernley_1997                  0.004344\n",
      "-----------------\n",
      "Calculating offsets for dataset solano_1997\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "-0.021628130741283474\n",
      "Number of overlapping stars:\n",
      "8\n",
      "{'offset_highres_residuals': [-0.021628130741283474], 'name_highres': ['solano_1997']}\n",
      "[('offset_highres_residuals', [-0.021628130741283474]), ('name_highres', ['solano_1997'])]\n",
      "  name_highres  offset_highres_residuals\n",
      "0  solano_1997                 -0.021628\n",
      "-----------------\n",
      "Calculating offsets for dataset wallerstein_2010\n",
      "Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:\n",
      "0.4042646912239418\n",
      "Number of overlapping stars:\n",
      "3\n",
      "{'offset_highres_residuals': [0.4042646912239418], 'name_highres': ['wallerstein_2010']}\n",
      "[('offset_highres_residuals', [0.4042646912239418]), ('name_highres', ['wallerstein_2010'])]\n",
      "       name_highres  offset_highres_residuals\n",
      "0  wallerstein_2010                  0.404265\n",
      "-_-ha-_-\n",
      "       name_highres  offset_highres_residuals\n",
      "0      fernley_1997                  0.004344\n",
      "0       solano_1997                 -0.021628\n",
      "0  wallerstein_2010                  0.404265\n",
      "======= STEP 3 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nyumbani/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/nyumbani/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= STEP 4 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nyumbani/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:32: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= STEP 5 ========\n",
      "======= STEP 6 ========\n"
     ]
    }
   ],
   "source": [
    "test_rrab = MetalBasisTypeSpecific(plot_name=\"name_here\").calc_FeH_program_stars()\n",
    "#test_rrc = MetalBasisTypeSpecific(plot_name=\"name_here\").calc_FeH_program_stars()\n",
    "#test_stuff = MetalBasisTypeSpecific(plot_name='name_here',star_type=\"RRc\").make_basis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
