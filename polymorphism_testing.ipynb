{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LitMetallicities():\n",
    "    '''\n",
    "    Class to \n",
    "    1.   read in Fe/H values from the literature \n",
    "    2.   initialize data set cross-referencing functionality\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        stem = \"./rrlyrae_metallicity/src/high_res_feh/\"\n",
    "\n",
    "        # stand-in that consists of our program star names\n",
    "        self.our_program_stars = pd.read_csv(stem + \"our_program_stars_names_only.csv\")\n",
    "        \n",
    "        # Fe/H from Layden+ 1994; this may serve as the common basis for RRabs\n",
    "        self.layden_feh = pd.read_csv(stem + \"layden_1994_abundances.dat\")\n",
    "        # RES: \"rather low\"\n",
    "        \n",
    "        # Fe/H Clementini+ 1995\n",
    "        self.clementini_feh = pd.read_csv(stem + \"clementini_1995_abundances.dat\")\n",
    "\n",
    "        # Fe/H Fernley+ 1996\n",
    "        self.fernley_feh = pd.read_csv(stem + \"fernley_1996_abundances.dat\")\n",
    "        # RES: 60,000, FeI & FeII, 5900-8100 A\n",
    "        \n",
    "        # log(eps) from Lambert+ 1996\n",
    "        self.lambert_logeps = pd.read_csv(stem + \"lambert_1996_abundances.dat\")\n",
    "        # RES: ~23,000, FeII + photometric models, 3600-9000 A\n",
    "        \n",
    "        # Fe/H from Wallerstein and Huang 2010, arXiv 1004.2017\n",
    "        self.wallerstein_feh = pd.read_csv(stem + \"wallerstein_huang_2010_abundances.dat\")\n",
    "        # RES: ~30,000, FeII\n",
    "        \n",
    "        # Fe/H from Chadid+ 2017 ApJ 835.2:187 (FeI and II lines)\n",
    "        self.chadid_feh = pd.read_csv(stem + \"chadid_2017_abundances.dat\")\n",
    "        # RES: 38000, FeI & FeII, 3400-9900 A\n",
    "\n",
    "        # Fe/H from Liu+ 2013 Res Ast Astroph 13:1307\n",
    "        self.liu_feh = pd.read_csv(stem + \"liu_2013_abundances.dat\")\n",
    "        # RES: ~60,000, FeI (& FeII?), 5100-6400 A\n",
    "\n",
    "        # Fe/H from Nemec+ 2013\n",
    "        self.nemec_feh = pd.read_csv(stem + \"nemec_2013_abundances.dat\")\n",
    "        # RES: ~65,000 or 36,000, FeI & FeII, 5150-5200 A\n",
    "\n",
    "        # Fe/H from Fernley+ 1997\n",
    "        self.fernley97_feh = pd.read_csv(stem + \"fernley_1997_abundances.dat\")\n",
    "        # RES: 60,000, two FeII lines, 5900-8100 A\n",
    "\n",
    "        # Fe/H from Solano+ 1997\n",
    "        self.solano_feh = pd.read_csv(stem + \"solano_1997_abundances.dat\")\n",
    "        # RES: 22,000 & 19,000, strong FeI lines, 4160-4390 & 4070-4490 A\n",
    "        \n",
    "        # Fe/H from Pancino+ 2015 MNRAS 447:2404\n",
    "        self.pacino_feh = pd.read_csv(stem + \"pacino_2015_abundances.dat\") \n",
    "        # RES: >30,000, FeI (weighted average), 4000-8500 A\n",
    "\n",
    "        # Fe/H from Sneden+ 2017\n",
    "        self.sneden_feh = pd.read_csv(stem + \"sneden_2017_abundances.dat\")\n",
    "        # RES: ~27,000 (at 5000 A), FeI & FeII, 3400-9000 A\n",
    "        \n",
    "        # convert Lambert's values, which are in terms of log(eps)\n",
    "        # FeH = log(epsFe) - log(epsFe,sol)\n",
    "        #     = log(epsFe) - log(NFe,sol/NH,sol)\n",
    "        #     = log(epsFe) - 7.51 # value of 7.51 from Anstee+ 1997, MNRAS\n",
    "        self.lambert_logeps['feh'] = np.subtract(self.lambert_logeps['log_eps_fe_spec'], 7.51) \n",
    "        \n",
    "        # average the values in Chadid from FeI and FeII lines\n",
    "        self.chadid_feh['feh'] = np.mean([self.chadid_feh['fehI'].values,self.chadid_feh['fehII'].values],axis=0)\n",
    "        \n",
    "        ## ## INCLUDE SINGLE DATA PT FROM KOLENBERG+ 2010? (SEE CHADID+ 2017, FIG. 7)\n",
    "        \n",
    "        # FYI: average Fe/H values in Liu+ 2013 which were taken at different phases\n",
    "        # liu_feh.groupby(liu_feh['name'], axis=0, as_index=False).mean()\n",
    "        \n",
    "        # FYI: average Fe/H values in Sneden+ 1997 which were taken at different epochs\n",
    "        # sneden_feh.groupby(sneden_feh['name'], axis=0, as_index=False).mean()\n",
    "        \n",
    "        # Fe/H from Kemper+ 1982; this might serve as the common basis for RRcs\n",
    "        self.kemper_feh = pd.read_csv(stem + \"kemper_1982_abundances.dat\")\n",
    "\n",
    "        # Fe/H from Govea+ 2014\n",
    "        ## ## note: Govea+ has abundances for each phase value, and this includes NLTE phases; how to get single Fe/H?\n",
    "        self.govea_feh = pd.read_csv(stem + \"govea_2014_abundances.dat\")\n",
    "        \n",
    "\n",
    "        #####################\n",
    "        \n",
    "        # initialize arrays: essential info\n",
    "        empir_spec_name_array = []\n",
    "        star_name_array = []\n",
    "        H_data_array = []\n",
    "        K_data_array = []\n",
    "        err_H_data_array = [] \n",
    "        err_K_data_array = []\n",
    "\n",
    "        # initialize arrays: other info\n",
    "        Hbet_data_array = []\n",
    "        err_Hbet_data_array = []\n",
    "        Hgam_data_array = []\n",
    "        err_Hgam_data_array = []\n",
    "        rHgam_data_array = [] # rescaled Hgamma\n",
    "        err_rHgam_data_array = []\n",
    "        Hdel_data_array = []\n",
    "        err_Hdel_data_array = []\n",
    "        Heps_data_array = []\n",
    "        err_Heps_data_array = []\n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        # make a list of all unique EMPIRICAL spectrum names\n",
    "        uniqueSpecNames = line_data.drop_duplicates(subset='empir_spec_name')['empir_spec_name']\n",
    "\n",
    "    def matchmaker(self, input_table, basis_table):\n",
    "        '''\n",
    "        Find what stars are common to two input tables, and return array of FeHs from the first table\n",
    "\n",
    "        INPUTS:\n",
    "        input_table: table I'm interested in checking for overlapping stars\n",
    "        basis_table: table with the names for which I am looking for repeats in the other table\n",
    "\n",
    "        OUTPUTS:\n",
    "        dictionary with\n",
    "        1. overlapping star names\n",
    "        2. FeHs from the input_table\n",
    "        3. FeHs from the basis_table\n",
    "        4. residuals in FeH: FeH_input - FeH_basis\n",
    "        '''\n",
    "\n",
    "        self.input_table = input_table\n",
    "        self.basis_table = basis_table\n",
    "            \n",
    "        input_FeH = [] # Fe/H of high-res study\n",
    "        basis_FeH = [] # Fe/H of basis (ex. Layden 1994)\n",
    "        name_array = [] # name of star\n",
    "\n",
    "        for row in range(0,len(input_table)): # scan over each row in input table\n",
    "            if (basis_table['name'] == input_table['name'][row]).any():\n",
    "                input_FeH = np.append(input_FeH,input_table['feh'][row])\n",
    "                basis_FeH = np.append(basis_FeH,basis_table.loc[basis_table['name'] == input_table['name'][row]]['feh'])\n",
    "                name_array = np.append(name_array,input_table['name'][row])\n",
    "\n",
    "        d = dict()\n",
    "        d['name'] = name_array\n",
    "        d['input_FeH'] = input_FeH\n",
    "        d['basis_FeH'] = basis_FeH\n",
    "        d['residuals_FeH'] = np.subtract(d['input_FeH'],d['basis_FeH'])\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MetalBasisTypeSpecific(LitMetallicities):\n",
    "    '''\n",
    "    Class to make a metallicity basis specific to the subtype: RRab (default) or RRc\n",
    "    '''\n",
    "\n",
    "    def __init__(self, plot_name, star_type=\"RRab\"): # , offset=False\n",
    "        super().__init__()\n",
    "        self.__plot_name = plot_name\n",
    "        self.__star_type = star_type\n",
    "        #self.__offset = offset\n",
    "\n",
    "        \n",
    "    def match_w_basis(self):\n",
    "        '''\n",
    "        Find what stars overlap with basis data set, and return star name, data set names, FeH values, residuals\n",
    "                \n",
    "        The functionality of LitMetallicities is inherited\n",
    "        N.b. There are no offsets applied yet (as are applied in Chadid+ 2017 plots)\n",
    "\n",
    "        INPUTS:\n",
    "        input_table: table of high-res-derived Fe/H values, which I want to cross-ref with a basis (like Layden 94 or Kemper 82)\n",
    "        basis_table: the table which serves as the basis set\n",
    "        plot_name: file name for saving a plot of the results\n",
    "\n",
    "        OUTPUTS:\n",
    "        dictionary with\n",
    "        1. overlapping star names\n",
    "        2. Fe/Hs from the input_table\n",
    "        3. Fe/Hs from basis set\n",
    "        '''\n",
    "\n",
    "        # define the basis data set (like Layden 1994 for RRabs, or Kemper+ 1982 for RRcs)\n",
    "        if self.__star_type == \"RRab\":\n",
    "            type_string = \"ab\"\n",
    "            basis_set = self.layden_feh\n",
    "            basis_string = \"Layden RRab basis set\" # string for plots\n",
    "        elif self.__star_type == \"RRc\":\n",
    "            type_string = \"c\"\n",
    "            basis_set = self.kemper_feh\n",
    "            basis_string = \"Kemper RRc basis set\"\n",
    "        else:\n",
    "            sys.exit(\"Error! No RR Lyrae subtype chosen.\")\n",
    "            \n",
    "        # match high-res studies with the basis set\n",
    "        dict_Lambert_1996 = self.matchmaker(self.lambert_logeps, basis_set) # Lambert+ 1996 (logeps has already been converted to Fe/H)\n",
    "        dict_Nemec_2013 = self.matchmaker(self.nemec_feh, basis_set) # Nemec+ 2013\n",
    "        dict_Chadid_2017 = self.matchmaker(self.chadid_feh, basis_set) # Chadid+ 2017\n",
    "        dict_Fernley_1997 = self.matchmaker(self.fernley97_feh, basis_set) # Fernley+ 1997\n",
    "        dict_Solano_1997 = self.matchmaker(self.solano_feh, basis_set) # Solano+ 1997\n",
    "        dict_Wallerstein_2010 = self.matchmaker(self.wallerstein_feh, basis_set) # Wallerstein 2010\n",
    "\n",
    "\n",
    "        # for Liu+ 2013, we need to group multiple Fe/H values by star name\n",
    "        # (the grouping is done here rather than further up because a bug causes the grouped column to disappear)\n",
    "        self.liu_feh_grouped = self.liu_feh.groupby(self.liu_feh['name'], axis=0, as_index=False).mean()\n",
    "        dict_Liu_2013 = self.matchmaker(self.liu_feh_grouped, basis_set) # Liu+ 2013\n",
    "        \n",
    "        # for Govea+ 2014, we need to group multiple Fe/H_I and Fe/H_II values by star name\n",
    "        # (the grouping is done here rather than further up because a bug causes the grouped column to disappear)\n",
    "        self.govea_feh_grouped = self.govea_feh.groupby(self.govea_feh['name'], axis=0, as_index=False).mean()\n",
    "        # now, average the Fe/H_I and Fe/H_II values to get single Fe/H values\n",
    "        self.govea_feh_grouped['feh'] = self.govea_feh_grouped[['feIh','feIIh']].mean(axis=1)\n",
    "        dict_Govea_2014 = self.matchmaker(self.govea_feh_grouped, basis_set) # Govea+ 2014\n",
    "        \n",
    "        \n",
    "        # merge dictionaries of literature Fe/H values\n",
    "        dict_collect = [dict_Lambert_1996, dict_Nemec_2013, dict_Liu_2013, dict_Chadid_2017,\n",
    "                        dict_Fernley_1997, dict_Solano_1997, dict_Wallerstein_2010, dict_Govea_2014]\n",
    "        \n",
    "        \n",
    "        ''' FYI\n",
    "        print('lambert')\n",
    "        print(dict_Lambert_1996)\n",
    "\n",
    "        print('nemec')\n",
    "        print(dict_Nemec_2013)\n",
    "        \n",
    "        print('liu')\n",
    "        print(dict_Liu_2013)     \n",
    "        \n",
    "        print('chadid')\n",
    "        print(dict_Chadid_2017)\n",
    "\n",
    "        print('fernley')\n",
    "        print(dict_Fernley_1997)\n",
    "        \n",
    "        print('solano')\n",
    "        print(dict_Solano_1997)  \n",
    "        \n",
    "        print('wallerstein')\n",
    "        print(dict_Wallerstein_2010)\n",
    "        \n",
    "        print('govea')\n",
    "        print(dict_Govea_2014)  \n",
    "        '''\n",
    "        \n",
    "        dict_merged = {}\n",
    "        for key in dict_Lambert_1996:\n",
    "            dict_merged[key] = tuple(dict_merged[key] for dict_merged in dict_collect)\n",
    "\n",
    "        # rename some things for neatness\n",
    "        basis_data_merged = np.hstack(dict_merged['basis_FeH'])\n",
    "        highres_data_merged = np.hstack(dict_merged['input_FeH'])\n",
    "        residuals_data_merged = np.hstack(dict_merged['residuals_FeH']) # Fe/H residuals: high_res minus basis values\n",
    "        names_merged = np.hstack(dict_merged['name'])\n",
    "\n",
    "        # return \n",
    "        # 1. overlapping Layden94 values\n",
    "        # 2. FeH values from lit source\n",
    "        # 3. Residuals between 1. and 2. (see Chadid+ 2017 ApJ 835:187, Figs. 5, 6, 7)\n",
    "        # 4. coefficients of best-fit line\n",
    "        # 5. offset in y to bring lit FeH values to match Chadid+ 2017 at FeH=-1.25 (see Chadid+ 2017 Figs. 5, 6)\n",
    "        # 6. Residuals (from 3.) minus the offset (from 5.)  (see Chadid+ 2017 Fig. 7)\n",
    "        # 7. The names of the stars (in same order as arrays for 1., 2., 3., 4.)\n",
    "        \n",
    "        d = dict()\n",
    "        d['basis_FeH'] = basis_data_merged\n",
    "        d['input_FeH'] = highres_data_merged\n",
    "        d['residuals'] = residuals_data_merged\n",
    "        #d['net_offset'] = net_offset # this needs to be ADDED to high-res study data to make it match Chadid\n",
    "        #d['residuals_shifted'] = np.add(residuals,net_offset)\n",
    "        d['name'] = names_merged\n",
    "        \n",
    "        return d\n",
    "   \n",
    "    def return_offsets((())):\n",
    "        '''\n",
    "        Depending on user choice of type of offset, calculate them here\n",
    "        \n",
    "        Return an offset for each data point and high-res study?\n",
    "        '''\n",
    "\n",
    "    def make_basis_via_offsets((())):\n",
    "        '''\n",
    "        apply offsets (which may be from RRabs, RRcs, combo, etc.) to data to make a basis\n",
    "        '''\n",
    "        '''\n",
    "        Make an actual basis, by\n",
    "        1.  retrieving cross-refs of high-res data sets and basis sets\n",
    "        2.  applying offsets (see, for example, Chadid+ 2017), of which there are a few choices\n",
    "        3.  and including some plotting functionality\n",
    "        '''\n",
    "        \n",
    "        # find best-fit line to Fe/H plot of high_res vs. basis \n",
    "        # (note that user may have used a flag to make Fe/H values be offset)\n",
    "        limits = [-3.0,0.5]\n",
    "        m_merged_highres, b_merged_highres = np.polyfit(basis_data_merged, highres_data_merged, 1)\n",
    "        line_highres = np.multiply(m_merged_highres,limits)+b_merged_highres # make best-fit line for high-res Fe/H\n",
    "        m_merged_resid, b_merged_resid = np.polyfit(basis_data_merged, residuals_data_merged, 1)\n",
    "        line_resid = np.multiply(m_merged_resid,limits)+b_merged_resid # make best-fit line for residuals\n",
    "            \n",
    "        # save a plot (high_res vs. basis on top; residuals vs. basis on bottom)\n",
    "        plt.clf()\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(10,10), sharex=True)\n",
    "        axs[0].plot([limits[0],limits[1]],[limits[0],limits[1]], linestyle='--') # make 1-to-1 line\n",
    "        axs[0].plot([limits[0],limits[1]],np.add(np.multiply(m_merged_highres,[limits[0],limits[1]]),b_merged_highres), linestyle='--') # best-fit line\n",
    "        axs[0].scatter(basis_data_merged, highres_data_merged) # input vs. basis\n",
    "        axs[0].set_xlim(limits[0], limits[1])\n",
    "        axs[0].set_ylabel(\"Fe/H, high-res\")\n",
    "        axs[0].set_title(\"m = \"+str(m_merged_highres)+\", b = \"+str(b_merged_highres)+\"; (blue line: 1-to-1; orange line: best fit)\")\n",
    "        axs[1].axhline(y=0, linestyle='--') # dashed line at y=0\n",
    "        axs[1].scatter(basis_data_merged, residuals_data_merged) # input vs. basis\n",
    "        axs[1].set_xlabel(\"Fe/H, \"+basis_string)\n",
    "        axs[1].set_ylabel('Fe/H Residuals: high-res minus basis set')\n",
    "        axs[1].set_title(\"m = \"+str(m_merged_resid)+\", b = \"+str(b_merged_resid)+\"; (blue line: zero)\")\n",
    "        fig.suptitle(\"Finding remapping relation between\\nhigh-res studies and basis dataset\\n(\"+type_string+\" subtype)\")\n",
    "        #fig.tight_layout()\n",
    "        plt.savefig(\"remapping_\"+self.__plot_name, overwrite=True)\n",
    "        plt.clf()\n",
    "        d['coeff_merged_highres'] = [m_merged_highres, b_merged_highres] # best-fit line coeffs for high-res vs. basis \n",
    "        d['coeff_merged_resid'] = [m_merged_resid, b_merged_resid] # best-fit line coeffs for (residuals: high-res minus basis) vs. basis \n",
    "\n",
    "\n",
    "    \n",
    "    def calc_FeH_program_stars(self):\n",
    "        '''\n",
    "        Calculate metallicities for the program stars which form the basis of the\n",
    "        metallicity calibration, by using the remapping relationships\n",
    "\n",
    "        INPUTS:\n",
    "        basis_set: basis set used for either RRab (such as Layden 1994) or RRc (such as Kemper+ 1982)\n",
    "        '''\n",
    "\n",
    "        # retrieve our own program stars and remap those of the right type\n",
    "        if self.__star_type == \"RRab\":\n",
    "            type_string = \"ab\"\n",
    "            basis_set = self.layden_feh\n",
    "            basis_string = \"Layden RRab basis set\" # string for plots\n",
    "        elif self.__star_type == \"RRc\":\n",
    "            type_string = \"c\"\n",
    "            basis_set = self.kemper_feh\n",
    "            basis_string = \"Kemper RRc basis set\"\n",
    "\n",
    "        # retrieve our stars here, and extract only those which conform to the right type\n",
    "        program_stars_subset = self.our_program_stars.loc[self.our_program_stars['type'] == type_string].reset_index()\n",
    "        \n",
    "        # find matches with the basis set\n",
    "        program_stars_subset_matched = self.matchmaker(program_stars_subset, basis_set)\n",
    "\n",
    "        # find the coefficients we're interested in\n",
    "        map_info = self.make_basis()\n",
    "        print(map_info)\n",
    "        \n",
    "        # remap metallicities via\n",
    "        # [Fe/H]_highres = m*[Fe/H]_basis_set + b   \n",
    "        program_stars_subset_matched['mapped_FeH'] = np.add(np.multiply(program_stars_subset_matched['basis_FeH'],\n",
    "                                                                        map_info['coeff_merged_highres'][0]),\n",
    "                                                            map_info['coeff_merged_highres'][1])\n",
    "        \n",
    "        print(program_stars_subset_matched.keys())\n",
    "        # save a plot of calibration program stars Fe/H\n",
    "        # post-mapped Fe/H vs. pre-mapped (i.e., basis set) Fe/H\n",
    "        limits = [-3.0,0.5]\n",
    "        plt.clf()\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(10,10))\n",
    "        axs.plot([limits[0],limits[1]],[limits[0],limits[1]], linestyle='--') # make 1-to-1 line\n",
    "        axs.scatter(program_stars_subset_matched['basis_FeH'], program_stars_subset_matched['mapped_FeH']) # input vs. basis\n",
    "        axs.set_xlim(limits[0], limits[1])\n",
    "        axs.set_ylabel(\"Fe/H, high-res\")\n",
    "        axs.set_xlabel(\"Fe/H, \"+basis_string)\n",
    "        #axs.set_title(\"m = \"+str(m_merged_highres)+\", b = \"+str(b_merged_highres))\n",
    "\n",
    "        fig.suptitle('Calculated Fe/H of calibration program stars\\n('+type_string+' subtype)')\n",
    "        #fig.tight_layout()\n",
    "        plt.savefig('calculated_FeH_'+self.__plot_name, overwrite=True)\n",
    "        plt.clf()\n",
    "    \n",
    "        '''\n",
    "        # write out\n",
    "        convert_to_df = pd.DataFrame.from_dict(dict_our_program_stars['name']) # initialize\n",
    "        convert_to_df.columns = ['name'] # rename the column\n",
    "        convert_to_df['mapped_feh'] = pd.DataFrame.from_dict(dict_our_program_stars['mapped_feh']) # add the remapped Fe/H\n",
    "        no_return = convert_to_df.to_csv(write_loc + \"mapped_feh.csv\") # write out ## ## note 2 things: 1., this should be appeneded to our .csv with EWs; 2. there is no phase info here yet\n",
    "        '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambert\n",
      "{'name': array(['DH Peg', 'T Sex'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.32, -1.56]), 'basis_FeH': array([-1.04, -1.18]), 'residuals_FeH': array([-0.28, -0.38])}\n",
      "nemec\n",
      "{'name': [], 'input_FeH': [], 'basis_FeH': [], 'residuals_FeH': array([], dtype=float64)}\n",
      "liu\n",
      "{'name': array(['DH Peg'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.09666667]), 'basis_FeH': array([-1.04]), 'residuals_FeH': array([-0.05666667])}\n",
      "chadid\n",
      "{'name': [], 'input_FeH': [], 'basis_FeH': [], 'residuals_FeH': array([], dtype=float64)}\n",
      "fernley\n",
      "{'name': array(['AE Boo', 'UY Cam', 'U Com', 'BX Leo', 'VZ Peg', 'AP Ser', 'T Sex',\n",
      "       'SX UMa'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.34, -1.51, -1.19, -1.21, -1.78, -1.43, -1.37, -1.45]), 'basis_FeH': array([-1.48, -1.06, -1.32, -1.23, -1.75, -1.37, -1.18, -1.82]), 'residuals_FeH': array([ 0.14, -0.45,  0.13,  0.02, -0.03, -0.06, -0.19,  0.37])}\n",
      "solano\n",
      "{'name': array(['BV Aqr', 'AE Boo', 'DH Peg', 'VZ Peg', 'AP Ser', 'T Sex', 'MT Tel',\n",
      "       'SX UMa'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.18, -1.18, -1.35, -1.63, -1.62, -1.27, -1.64, -1.63]), 'basis_FeH': array([-1.48, -1.48, -1.04, -1.75, -1.37, -1.18, -1.82, -1.82]), 'residuals_FeH': array([ 0.3 ,  0.3 , -0.31,  0.12, -0.25, -0.09,  0.18,  0.19])}\n",
      "wallerstein\n",
      "{'name': array(['DH Peg', 'RU Psc', 'RZ Cep'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.53, -2.04, -2.1 ]), 'basis_FeH': array([-1.04, -1.65, -1.48]), 'residuals_FeH': array([-0.49, -0.39, -0.62])}\n",
      "govea\n",
      "{'name': array(['YZ Cap'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.49428571]), 'basis_FeH': array([-1.29]), 'residuals_FeH': array([-0.20428571])}\n",
      "[{'name': array(['DH Peg', 'T Sex'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.32, -1.56]), 'basis_FeH': array([-1.04, -1.18]), 'residuals_FeH': array([-0.28, -0.38])}, {'name': [], 'input_FeH': [], 'basis_FeH': [], 'residuals_FeH': array([], dtype=float64)}, {'name': array(['DH Peg'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.09666667]), 'basis_FeH': array([-1.04]), 'residuals_FeH': array([-0.05666667])}, {'name': [], 'input_FeH': [], 'basis_FeH': [], 'residuals_FeH': array([], dtype=float64)}, {'name': array(['AE Boo', 'UY Cam', 'U Com', 'BX Leo', 'VZ Peg', 'AP Ser', 'T Sex',\n",
      "       'SX UMa'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.34, -1.51, -1.19, -1.21, -1.78, -1.43, -1.37, -1.45]), 'basis_FeH': array([-1.48, -1.06, -1.32, -1.23, -1.75, -1.37, -1.18, -1.82]), 'residuals_FeH': array([ 0.14, -0.45,  0.13,  0.02, -0.03, -0.06, -0.19,  0.37])}, {'name': array(['BV Aqr', 'AE Boo', 'DH Peg', 'VZ Peg', 'AP Ser', 'T Sex', 'MT Tel',\n",
      "       'SX UMa'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.18, -1.18, -1.35, -1.63, -1.62, -1.27, -1.64, -1.63]), 'basis_FeH': array([-1.48, -1.48, -1.04, -1.75, -1.37, -1.18, -1.82, -1.82]), 'residuals_FeH': array([ 0.3 ,  0.3 , -0.31,  0.12, -0.25, -0.09,  0.18,  0.19])}, {'name': array(['DH Peg', 'RU Psc', 'RZ Cep'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.53, -2.04, -2.1 ]), 'basis_FeH': array([-1.04, -1.65, -1.48]), 'residuals_FeH': array([-0.49, -0.39, -0.62])}, {'name': array(['YZ Cap'],\n",
      "      dtype='<U32'), 'input_FeH': array([-1.49428571]), 'basis_FeH': array([-1.29]), 'residuals_FeH': array([-0.20428571])}]\n",
      "{'input_FeH': array([-1.32      , -1.56      , -1.09666667, -1.34      , -1.51      ,\n",
      "       -1.19      , -1.21      , -1.78      , -1.43      , -1.37      ,\n",
      "       -1.45      , -1.18      , -1.18      , -1.35      , -1.63      ,\n",
      "       -1.62      , -1.27      , -1.64      , -1.63      , -1.53      ,\n",
      "       -2.04      , -2.1       , -1.49428571]), 'residuals': array([-0.28      , -0.38      , -0.05666667,  0.14      , -0.45      ,\n",
      "        0.13      ,  0.02      , -0.03      , -0.06      , -0.19      ,\n",
      "        0.37      ,  0.3       ,  0.3       , -0.31      ,  0.12      ,\n",
      "       -0.25      , -0.09      ,  0.18      ,  0.19      , -0.49      ,\n",
      "       -0.39      , -0.62      , -0.20428571]), 'basis_FeH': array([-1.04, -1.18, -1.04, -1.48, -1.06, -1.32, -1.23, -1.75, -1.37,\n",
      "       -1.18, -1.82, -1.48, -1.48, -1.04, -1.75, -1.37, -1.18, -1.82,\n",
      "       -1.82, -1.04, -1.65, -1.48, -1.29]), 'coeff_merged_highres': [0.43632009089288126, -0.87023613409548928], 'name': array(['DH Peg', 'T Sex', 'DH Peg', 'AE Boo', 'UY Cam', 'U Com', 'BX Leo',\n",
      "       'VZ Peg', 'AP Ser', 'T Sex', 'SX UMa', 'BV Aqr', 'AE Boo', 'DH Peg',\n",
      "       'VZ Peg', 'AP Ser', 'T Sex', 'MT Tel', 'SX UMa', 'DH Peg', 'RU Psc',\n",
      "       'RZ Cep', 'YZ Cap'],\n",
      "      dtype='<U32'), 'coeff_merged_resid': [-0.56367990910711896, -0.87023613409548928]}\n",
      "dict_keys(['name', 'input_FeH', 'mapped_FeH', 'basis_FeH', 'residuals_FeH'])\n"
     ]
    }
   ],
   "source": [
    "#test_rrab = MetalBasisTypeSpecific(plot_name='name_here',offset=True).calc_FeH_program_stars()\n",
    "test_rrc = MetalBasisTypeSpecific(plot_name='name_here',star_type=\"RRc\").calc_FeH_program_stars()\n",
    "\n",
    "#test_stuff = MetalBasisTypeSpecific(plot_name='name_here',star_type=\"RRc\").make_basis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'basis_FeH': array([-1.04, -1.18, -1.04, -1.48, -1.06, -1.32, -1.23, -1.75, -1.37,\n",
      "       -1.18, -1.82, -1.48, -1.48, -1.04, -1.75, -1.37, -1.18, -1.82,\n",
      "       -1.82, -1.04, -1.65, -1.48]), 'coeff_merged_highres': [0.43997057186033556, -0.86238029905352753], 'name': array(['DH Peg', 'T Sex', 'DH Peg', 'AE Boo', 'UY Cam', 'U Com', 'BX Leo',\n",
      "       'VZ Peg', 'AP Ser', 'T Sex', 'SX UMa', 'BV Aqr', 'AE Boo', 'DH Peg',\n",
      "       'VZ Peg', 'AP Ser', 'T Sex', 'MT Tel', 'SX UMa', 'DH Peg', 'RU Psc',\n",
      "       'RZ Cep'],\n",
      "      dtype='<U32'), 'residuals': array([-0.28      , -0.38      , -0.05666667,  0.14      , -0.45      ,\n",
      "        0.13      ,  0.02      , -0.03      , -0.06      , -0.19      ,\n",
      "        0.37      ,  0.3       ,  0.3       , -0.31      ,  0.12      ,\n",
      "       -0.25      , -0.09      ,  0.18      ,  0.19      , -0.49      ,\n",
      "       -0.39      , -0.62      ]), 'input_FeH': array([-1.32      , -1.56      , -1.09666667, -1.34      , -1.51      ,\n",
      "       -1.19      , -1.21      , -1.78      , -1.43      , -1.37      ,\n",
      "       -1.45      , -1.18      , -1.18      , -1.35      , -1.63      ,\n",
      "       -1.62      , -1.27      , -1.64      , -1.63      , -1.53      ,\n",
      "       -2.04      , -2.1       ]), 'coeff_merged_resid': [-0.56002942813966494, -0.86238029905352864]}\n"
     ]
    }
   ],
   "source": [
    "print(test_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MatchmakerLayden(LitMetallicities):\n",
    "\n",
    "        def __init__(self, plot_name, offset=False):\n",
    "                super().__init__()\n",
    "                self.__plot_name = plot_name\n",
    "\n",
    "        \n",
    "        def matchmaker(self, plot_name, offset=False):\n",
    "                '''\n",
    "                Find what stars overlap with Layden 1994, and return star name, FeH values, residuals\n",
    "                \n",
    "                The functionality of LitMetallicities is inherited, and we just add Chadid+ 17-style offsets, a best-fit line, and plotting functionality\n",
    "\n",
    "                INPUTS:\n",
    "                input_table: table of likely high-res-derived Fe/H values of RRabs, which I want to cross-ref with Layden 94\n",
    "                layden_table: the layden table, which serves as the basis set\n",
    "                plot_name: file name for saving a plot of the results\n",
    "\n",
    "                OUTPUTS:\n",
    "                dictionary with\n",
    "                1. overlapping star names\n",
    "                2. Fe/Hs from the input_table\n",
    "                3. Fe/Hs from Layden\n",
    "                '''\n",
    "    \n",
    "                # best-fit line\n",
    "                coeff = np.polyfit(laydenFeH, residuals, 1)\n",
    "                limits = [-3.0,0.5]\n",
    "                line = np.multiply(coeff[0],limits)+coeff[1]\n",
    "\n",
    "                ## ## IT APPEARS THE OFFSET FLAG IS DEPRECATED HERE?\n",
    "                # if there needs to be an offset (like in Fig. 6 of Chadid+ 2017)\n",
    "                chadid_y_125 = -0.10583621694962 # from Chadid line at Fe/H=-1.25\n",
    "                this_y_125 = np.multiply(coeff[0],-1.25)+coeff[1] # y-value of this line at Fe/H=-1.25\n",
    "                net_offset = chadid_y_125 - this_y_125 # offset needed to move line\n",
    "                print('Y_offset to add to residuals in order to overlap with Chadid+ 2017 at Fe/H=-1.25:')\n",
    "                print(net_offset)\n",
    "                print('Number of overlapping stars:')\n",
    "                print(len(residuals))\n",
    "                line_offset = np.add(line,net_offset)\n",
    "    \n",
    "                # save a plot\n",
    "                '''\n",
    "                plt.scatter(laydenFeH, np.subtract(inputFeH,laydenFeH))\n",
    "                plt.plot([-3.0,0.5], [0., 0.], linestyle='--')\n",
    "                plt.plot(limits, line)\n",
    "                plt.plot(limits, line_offset)\n",
    "                #plt.xlim([-3.0,0.5])\n",
    "                #plt.ylim([-0.6,0.6])\n",
    "                plt.xlabel('[Fe/H]_Lay94')\n",
    "                plt.ylabel('[Fe/H]_input - [Fe/H]_Lay94')\n",
    "                plt.title('residuals between '+str(plot_name)+' and Lay94\\ny=mx+b, m='+str(coeff[0])+', b='+str(coeff[1])+'\\n offset '+str(net_offset))\n",
    "                plt.savefig(plot_name+'_test_180708.png')\n",
    "                #plt.show()\n",
    "                plt.clf()\n",
    "                '''\n",
    "            \n",
    "                # return \n",
    "                # 1. overlapping Layden94 values\n",
    "                # 2. FeH values from lit source\n",
    "                # 3. Residuals between 1. and 2. (see Chadid+ 2017 ApJ 835:187, Figs. 5, 6, 7)\n",
    "                # 4. coefficients of best-fit line\n",
    "                # 5. offset in y to bring lit FeH values to match Chadid+ 2017 at FeH=-1.25 (see Chadid+ 2017 Figs. 5, 6)\n",
    "                # 6. Residuals (from 3.) minus the offset (from 5.)  (see Chadid+ 2017 Fig. 7)\n",
    "                # 7. The names of the stars (in same order as arrays for 1., 2., 3., 4.)\n",
    "        \n",
    "                d = dict()\n",
    "                d['laydenFeH'] = laydenFeH\n",
    "                d['inputFeH'] = inputFeH\n",
    "                d['residuals'] = residuals\n",
    "                d['coeff'] = coeff\n",
    "                d['net_offset'] = net_offset # this needs to be ADDED to high-res study data to make it match Chadid\n",
    "                d['residuals_shifted'] = np.add(residuals,net_offset)\n",
    "                d['name'] = nameArray\n",
    "        \n",
    "                return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "junk = LitMetallicities()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
